{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide the name of the file you wish to check.  (do NOT include .csv in file name) A_1_URE_MS_GH_LI_06_25_18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_1_URE_MS_GH_LI_06_25_18.csv has the following properties:\n",
      "  - Acceptable blank readings\n",
      "  - A calibration curve r-squared value of 0.899899494585602\n",
      "  - A CORRECTED curve r-squared value of 0.9527330154900056\n",
      "  - Greater than 10% variance in 1 sample(s)\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "\n",
    "sheet_name = input('Provide the name of the file you wish to check.  (do NOT include .csv in file name)')\n",
    "\n",
    "sheet_name = sheet_name + '.csv'\n",
    "\n",
    "filea = sheet_name.split('_')[-6]\n",
    "fileb = sheet_name.split('_')[-5]\n",
    "filec = sheet_name.split('_')[-4]\n",
    "\n",
    "folder = \"Lab_Sheets/\" + str(filea) + '_' + str(fileb) + '_' + str(filec) + '/'\n",
    "\n",
    "datasheet = '/Users/' + user + '/Desktop/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheet)\n",
    "\n",
    "\n",
    "# Reading working file as dataframe in pandas\n",
    "\n",
    "lab_data = pd.read_csv(sheet_name)\n",
    "\n",
    "\n",
    "# Pulling parts of name to identify sheet for naming/moving\n",
    "\n",
    "title = sheet_name.split('_')[2]\n",
    "\n",
    "\n",
    "print(sheet_name + ' has the following properties:')\n",
    "### SCREENING FOR PRESENCE OF DATA            \n",
    "\n",
    "\n",
    "\n",
    "# Checking for data - skipping remainder of code (breaking loop) if there is no data\n",
    "\n",
    "if not np.isnan(lab_data.Absorbance[4]):\n",
    "\n",
    "#                     break\n",
    "\n",
    "\n",
    "#                 # Continuing if data is found\n",
    "\n",
    "#                 else:\n",
    "\n",
    "    # Identifying sheet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### SCREENING BLANKS                        \n",
    "\n",
    "\n",
    "\n",
    "    # Creating empty lists to append with 'blanks' information\n",
    "\n",
    "    blanks_abs = []\n",
    "\n",
    "\n",
    "    # Identifying blank absorbances based on 'Type' column\n",
    "\n",
    "    for n in range(len(lab_data)):\n",
    "        if lab_data.Type[n] == 'B':\n",
    "            blanks_abs.append(float(lab_data.Absorbance[n]))\n",
    "\n",
    "\n",
    "    # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "\n",
    "    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "\n",
    "\n",
    "    # If the list of acceptable blanks has fewer than three values, set must be repeated\n",
    "\n",
    "    if len(good_blanks) <= 2 :\n",
    "\n",
    "\n",
    "        print(\"  - Blank readings are questionable:\" + str(blank_abs))\n",
    "\n",
    "\n",
    "\n",
    "    # If the list of acceptable blanks has three good values, set is acceptable   \n",
    "\n",
    "    else:\n",
    "\n",
    "\n",
    "        print(\"  - Acceptable blank readings\")\n",
    "\n",
    "\n",
    "### SCREENING CURVES\n",
    "\n",
    "## code will check if curve can be \n",
    "## adjusted to produce and acceptable r^2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Creating empty lists to append with curve information\n",
    "\n",
    "        curve_absorbance = []\n",
    "        curve_concentration = []\n",
    "\n",
    "\n",
    "        # Identifying standard absorbances based on 'Type' column\n",
    "\n",
    "        for n in range(len(lab_data)):\n",
    "            if lab_data.Type[n] == 'C':\n",
    "\n",
    "\n",
    "                # Appending calibration data to appropriate list for curve analysis\n",
    "\n",
    "                curve_absorbance.append(float(lab_data.Absorbance[n]))\n",
    "                curve_concentration.append(float(lab_data.Sample_ID[n]))\n",
    "\n",
    "\n",
    "        # Calculating r^2 value for two calibration data lists with lin.regress module\n",
    "\n",
    "        slope, intercept, r_value1, p_value, std_err = stats.linregress(curve_absorbance, curve_concentration)\n",
    "\n",
    "\n",
    "        # Creating conditional for screening based on r^2 value... using a matrix to calculate optional r^2 values based\n",
    "        # on removal of one curve point\n",
    "\n",
    "        if r_value1**2 < 0.95:\n",
    "\n",
    "            # Creating pandas dataframe for analysis\n",
    "\n",
    "            columns = [['Conc', 'Abs']]\n",
    "\n",
    "            curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "            # Assigning values to concentration and absorbance columns\n",
    "\n",
    "            curve['Conc'] = curve_concentration\n",
    "            curve['Abs'] = curve_absorbance\n",
    "\n",
    "\n",
    "            # Defining the size of the possible removal matrix\n",
    "\n",
    "            points = len(curve_concentration) # Total number of datapoints\n",
    "\n",
    "\n",
    "            # Creating a matrix via a numpy array \n",
    "\n",
    "            array = np.identity(points)\n",
    "\n",
    "\n",
    "            # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "            for i in range(array.shape[1]):\n",
    "\n",
    "                curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "            # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "            for i in range(1,points):\n",
    "\n",
    "                array = np.identity(i)\n",
    "                array = np.vstack([array, [1]*i])\n",
    "\n",
    "                if array.shape[0] != 12:\n",
    "                    for j in range(12 - array.shape[0]):\n",
    "                        array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                    for k in range(array.shape[1]):\n",
    "\n",
    "                        curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "            # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "            columns = []\n",
    "            slopes = []\n",
    "            intercepts = []\n",
    "            rvals = []\n",
    "            pvals = []\n",
    "            stderrs = []\n",
    "\n",
    "            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "            for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                columns.append(column)\n",
    "\n",
    "\n",
    "                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                count = 0\n",
    "                conc = []\n",
    "                absorb = []\n",
    "\n",
    "\n",
    "                # Running conditional by row in column\n",
    "\n",
    "                for i in curve[column]: \n",
    "\n",
    "\n",
    "                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                    if i < 1:\n",
    "                        conc.append(curve.iloc[count,0])\n",
    "                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                    # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                    count = count + 1\n",
    "\n",
    "\n",
    "                # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                slopes.append(slope)\n",
    "                intercepts.append(inter)\n",
    "                rvals.append(r_val**2)\n",
    "                pvals.append(p_val)\n",
    "                stderrs.append(std)\n",
    "\n",
    "\n",
    "            # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "            parameters['Column'] = columns\n",
    "            parameters['Slope'] = slopes\n",
    "            parameters['Intercept'] = intercepts\n",
    "            parameters['R_Sq'] = rvals\n",
    "            parameters['P_Val'] = pvals\n",
    "            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "            ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "            #print(parameters['R_Sq'].max())\n",
    "            #print(parameters)\n",
    "\n",
    "\n",
    "            # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "            # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "            # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "            if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                columns = []\n",
    "                slopes = []\n",
    "                intercepts = []\n",
    "                rvals = []\n",
    "                pvals = []\n",
    "                stderrs = []\n",
    "\n",
    "                parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                    columns.append(column)\n",
    "\n",
    "\n",
    "                    # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                    count = 0\n",
    "                    conc = []\n",
    "                    absorb = []\n",
    "\n",
    "\n",
    "                    # Running conditional by row in column\n",
    "\n",
    "                    for i in curve[column]: \n",
    "\n",
    "\n",
    "                        # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                        if i < 1:\n",
    "                            conc.append(curve.iloc[count,0])\n",
    "                            absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                        # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                        count = count + 1\n",
    "\n",
    "\n",
    "                    # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                    slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                    slopes.append(slope)\n",
    "                    intercepts.append(inter)\n",
    "                    rvals.append(r_val**2)\n",
    "                    pvals.append(p_val)\n",
    "                    stderrs.append(std)\n",
    "\n",
    "                # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                parameters['Column'] = columns\n",
    "                parameters['Slope'] = slopes\n",
    "                parameters['Intercept'] = intercepts\n",
    "                parameters['R_Sq'] = rvals\n",
    "                parameters['P_Val'] = pvals\n",
    "                parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "\n",
    "            print(\"  - A calibration curve r-squared value of \" + str(r_value1**2))\n",
    "            print(\"  - A CORRECTED curve r-squared value of \" + str(parameters.R_Sq.max()))                    \n",
    "\n",
    "### SCREENING FOR SAMPLE ORIGINAL/DUPLICATE VARIATION                                            \n",
    "\n",
    "\n",
    "\n",
    "        # If the calibration data is acceptable:                 \n",
    "\n",
    "        else: \n",
    "\n",
    "            # Defining which rows contain sample data\n",
    "\n",
    "            print(\"  - A calibration curve r-squared value of \" + str(r_value1**2))\n",
    "\n",
    "        sample_data = lab_data[lab_data.Type != 'C']\n",
    "        sample_data = sample_data[sample_data.Type != 'B']\n",
    "\n",
    "\n",
    "        # Creating new dataframe with only ID & absorbance\n",
    "\n",
    "        sample_data_ab = sample_data[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "\n",
    "        # Grouping sample data based on unique ID\n",
    "\n",
    "        sample_data_g = sample_data_ab.groupby('Sample_ID')\n",
    "\n",
    "\n",
    "        # Merging and creating a new dataframe for original/duplicate variance values (max-min/max)\n",
    "\n",
    "        sample_data_var = sample_data_ab.merge((abs((sample_data_g.max() - sample_data_g.min())) / (sample_data_g.max())), on='Sample_ID')\n",
    "\n",
    "\n",
    "        # Create conditional based on variance column\n",
    "\n",
    "        U_Re_Run = []\n",
    "        N_Re_Run = []\n",
    "\n",
    "        for i, row in sample_data_var.iterrows():\n",
    "            if float(row['Absorbance_y']) > 0.1:\n",
    "\n",
    "\n",
    "                # Adding sample ID information to appropriate list if variance is unacceptable\n",
    "\n",
    "                if title == \"URE\":\n",
    "                    U_Re_Run.append(row['Sample_ID'])\n",
    "                elif title == \"NIT\":\n",
    "                    N_Re_Run.append(row['Sample_ID'])\n",
    "\n",
    "        U_Run_List = set(U_Re_Run)    \n",
    "        N_Run_List = set(N_Re_Run)\n",
    "\n",
    "        if title == \"URE\":\n",
    "\n",
    "            print('  - Greater than 10% variance in ' + str(len(U_Run_List)) + \" sample(s)\")\n",
    "\n",
    "        elif title == 'NIT':\n",
    "\n",
    "            print('  - Greater than 10% variance in ' + str(len(N_Run_List)) + \" sample(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
