{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_screening Code\n",
    "#### Author: Rachel Veenstra\n",
    "#### Date Created: 04-03-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR_USB\n",
      "RV_CTS\n",
      "USB_Indiana\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/USB_Indiana\\A_5_URE_LMR_IN_USB_03_21_19.csv\n",
      "0.9999138536496541\n",
      "   Column     Slope  Intercept      R_Sq         P_Val    StdErr\n",
      "0    (0,)  0.000353   0.120326  0.519684  1.230824e-02  0.000113\n",
      "1    (1,)  0.000353   0.120326  0.519684  1.230824e-02  0.000113\n",
      "2    (2,)  0.000353   0.120500  0.519628  1.231522e-02  0.000113\n",
      "3    (3,)  0.000358   0.101110  0.537632  1.024081e-02  0.000111\n",
      "4    (4,)  0.000358   0.101950  0.537364  1.026943e-02  0.000111\n",
      "5    (5,)  0.000358   0.101950  0.537364  1.026943e-02  0.000111\n",
      "6    (6,)  0.000359   0.092442  0.545314  9.447433e-03  0.000109\n",
      "7    (7,)  0.000359   0.089116  0.546341  9.345245e-03  0.000109\n",
      "8    (8,)  0.000359   0.089892  0.546090  9.370168e-03  0.000109\n",
      "9    (9,)  0.000268   0.148162  0.387503  4.081082e-02  0.000112\n",
      "10  (10,)  0.000551   0.007226  0.999914  1.322394e-19  0.000002\n",
      "11  (11,)  0.000266   0.149185  0.386900  4.101407e-02  0.000111\n",
      "Good curve\n",
      "USB_Iowa\n",
      "USB_Minnesota\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/USB_Minnesota\\A_2_NIT_LMR_MN_USB_03_15_19.csv\n",
      "0.16156277990113285\n",
      "   Column     Slope  Intercept      R_Sq     P_Val    StdErr\n",
      "0    (0,) -0.000021   0.099696  0.161563  0.220412  0.000016\n",
      "1    (1,) -0.000020   0.099391  0.160012  0.222850  0.000016\n",
      "2    (2,) -0.000020   0.099391  0.160012  0.222850  0.000016\n",
      "3    (3,) -0.000011   0.060889  0.073854  0.418860  0.000014\n",
      "4    (4,) -0.000011   0.060148  0.073994  0.418402  0.000013\n",
      "5    (5,) -0.000011   0.055704  0.077210  0.408059  0.000012\n",
      "6    (6,) -0.000013   0.078852  0.081202  0.395687  0.000015\n",
      "7    (7,) -0.000013   0.078963  0.080639  0.397403  0.000015\n",
      "8    (8,) -0.000013   0.079037  0.080276  0.398515  0.000015\n",
      "9    (9,) -0.000013   0.076087  0.062798  0.457338  0.000016\n",
      "10  (10,) -0.000013   0.076087  0.062798  0.457338  0.000016\n",
      "11  (11,) -0.000013   0.076000  0.062037  0.460167  0.000016\n",
      "0.31306684319162675\n",
      "Bad Curve\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/USB_Minnesota\\A_2_URE_LMR_MN_USB_03_15_19.csv\n",
      "0.18170204402515733\n",
      "   Column         Slope  Intercept      R_Sq     P_Val        StdErr\n",
      "0    (0,)  1.179346e-07   0.007533  0.024954  0.642727  2.457340e-07\n",
      "1    (1,)  1.179346e-07   0.007533  0.024954  0.642727  2.457340e-07\n",
      "2    (2,)  1.684780e-07   0.007359  0.049927  0.508963  2.449802e-07\n",
      "3    (3,)  1.245272e-07   0.007528  0.029086  0.616115  2.398227e-07\n",
      "4    (4,)  1.552928e-07   0.007388  0.044347  0.534247  2.402981e-07\n",
      "5    (5,)  1.245272e-07   0.007528  0.029086  0.616115  2.398227e-07\n",
      "6    (6,)  1.201598e-07   0.007632  0.032251  0.597243  2.194057e-07\n",
      "7    (7,)  1.845311e-07   0.007078  0.181702  0.191104  1.305342e-07\n",
      "8    (8,)  1.330341e-07   0.007521  0.033998  0.587313  2.363776e-07\n",
      "9    (9,)  2.879055e-08   0.007509  0.001290  0.916508  2.670363e-07\n",
      "10  (10,)  1.497109e-07   0.007449  0.031459  0.601853  2.768953e-07\n",
      "11  (11,)  2.706312e-07   0.007389  0.104858  0.331331  2.635741e-07\n",
      "0.28782836724991967\n",
      "Bad Curve\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You have 28.0 unique samples (not including duplicates) to re-run for Ureides in USB_Minnesota. How many of these do you wish to run per set? 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 sheets for 56 total samples.\n",
      "New lab sheets saved as E_1_URE_LMR_MN_00_00_00.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You have 28.0 unique samples (not including duplicates) to re-run for Nitrates in USB_Minnesota. How many of these do you wish to run per set? 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 sheets for 56 total samples.\n",
      "New lab sheets saved as E_1_NIT_LMR_MN_00_00_00.csv\n",
      "USB_South_Dakota\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Setting loop for iterating through files WITHIN folders IN the specified folder\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    \n",
    "    \n",
    "    # Using \"try\" loop in the event that a folder is empty\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        \n",
    "        # Looping through every file in a folder\n",
    "        \n",
    "        for loc in folder:\n",
    "            \n",
    "            \n",
    "            # Identifying working folder\n",
    "            \n",
    "            print(loc)\n",
    "\n",
    "            folder_loc = datasheets + loc\n",
    "\n",
    "            glob.os.chdir(folder_loc)\n",
    "            \n",
    "            \n",
    "            # Grabbing all csv files in specified folder\n",
    "\n",
    "            all_datasheets = glob.glob(folder_loc + \"/*.csv\")\n",
    "            \n",
    "            \n",
    "            # Creating empty lists to append with ID's that fail quality screening\n",
    "\n",
    "            N_Re_Run = []\n",
    "            U_Re_Run = []\n",
    "            \n",
    "            \n",
    "            # Screening each sheet individually\n",
    "\n",
    "            for sheet in all_datasheets:\n",
    "\n",
    "                \n",
    "                # Reading working file as dataframe in pandas\n",
    "                \n",
    "                lab_data = pd.read_csv(sheet)\n",
    "                \n",
    "                \n",
    "                # Pulling parts of name to identify sheet for naming/moving\n",
    "\n",
    "                sheet_name = sheet.split('\\\\')[-1]\n",
    "                title = sheet_name.split('_')[2]\n",
    "            \n",
    "            \n",
    "                # Checking for data - skipping remainder of code (breaking loop) if there is no data\n",
    "\n",
    "                if np.isnan(lab_data.Absorbance[0]):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                # Continuing if data is found\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # Identifying sheet\n",
    "                    \n",
    "                    print(sheet)\n",
    "\n",
    "\n",
    "                    # Creating empty lists to append with curve information\n",
    "                    \n",
    "                    curve_absorbance = []\n",
    "                    curve_concentration = []\n",
    "\n",
    "                    \n",
    "                    # Identifying standard absorbances based on 'Type' column\n",
    "                    \n",
    "                    for n in range(len(lab_data)):\n",
    "                        if lab_data.Type[n] == 'C':\n",
    "                            \n",
    "                            \n",
    "                            # Appending calibration data to appropriate list for curve analysis\n",
    "                            \n",
    "                            curve_absorbance.append(float(lab_data.Absorbance[n]))\n",
    "                            curve_concentration.append(float(lab_data.Sample_ID[n]))\n",
    "\n",
    "\n",
    "                # Calculating r^2 value for two calibration data lists with lin.regress module\n",
    "\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(curve_absorbance, curve_concentration)\n",
    "\n",
    "                \n",
    "                # Creating conditional for screening based on r^2 value\n",
    "                \n",
    "                if r_value**2 < 0.95:\n",
    "                \n",
    "                    \n",
    "                    columns = [['Conc', 'Abs']]\n",
    "                    \n",
    "                    \n",
    "                    curve = pd.DataFrame(columns = columns)\n",
    "                    \n",
    "\n",
    "                    curve['Conc'] = curve_concentration\n",
    "                    curve['Abs'] = curve_absorbance\n",
    "                    \n",
    "\n",
    "                    points = len(curve_concentration) # Total number\n",
    "\n",
    "                    array = np.identity(points)\n",
    "                    \n",
    "\n",
    "                    for i in range(array.shape[1]):\n",
    "\n",
    "                        curve[str(i)] = array[:,i]\n",
    "\n",
    "                        \n",
    "                    for i in range(1,points):\n",
    "\n",
    "                        array = np.identity(i)\n",
    "                        array = np.vstack([array, [1]*i])\n",
    "\n",
    "                        if array.shape[0] != 12:\n",
    "                            for j in range(12 - array.shape[0]):\n",
    "                                array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                            for k in range(array.shape[1]):\n",
    "\n",
    "                                curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "                                \n",
    "                                \n",
    "                    columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                    columns = []\n",
    "                    slopes = []\n",
    "                    intercepts = []\n",
    "                    rvals = []\n",
    "                    pvals = []\n",
    "                    stderrs = []\n",
    "\n",
    "                    parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "                    for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                        columns.append(column)\n",
    "\n",
    "                        count = 0\n",
    "                        conc = []\n",
    "                        absorb = []\n",
    "\n",
    "\n",
    "                        for i in curve[column]: \n",
    "                            if i < 1:\n",
    "                                conc.append(curve.iloc[count,0])\n",
    "                                absorb.append(curve.iloc[count,1])\n",
    "                            count = count + 1\n",
    "\n",
    "                        slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                        slopes.append(slope)\n",
    "                        intercepts.append(inter)\n",
    "                        rvals.append(r_val**2)\n",
    "                        pvals.append(p_val)\n",
    "                        stderrs.append(std)\n",
    "\n",
    "                    parameters['Column'] = columns\n",
    "                    parameters['Slope'] = slopes\n",
    "                    parameters['Intercept'] = intercepts\n",
    "                    parameters['R_Sq'] = rvals\n",
    "                    parameters['P_Val'] = pvals\n",
    "                    parameters['StdErr'] = stderrs\n",
    "\n",
    "                    print(parameters.R_Sq.max())\n",
    "                    print(parameters)\n",
    "\n",
    "                    if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "                        columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                        columns = []\n",
    "                        slopes = []\n",
    "                        intercepts = []\n",
    "                        rvals = []\n",
    "                        pvals = []\n",
    "                        stderrs = []\n",
    "\n",
    "                        parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "                        for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                            columns.append(column)\n",
    "\n",
    "                            count = 0\n",
    "                            conc = []\n",
    "                            absorb = []\n",
    "\n",
    "\n",
    "                            for i in curve[column]: \n",
    "                                if i < 1:\n",
    "                                    conc.append(curve.iloc[count,0])\n",
    "                                    absorb.append(curve.iloc[count,1])\n",
    "                                count = count + 1\n",
    "\n",
    "                            slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                            slopes.append(slope)\n",
    "                            intercepts.append(inter)\n",
    "                            rvals.append(r_val**2)\n",
    "                            pvals.append(p_val)\n",
    "                            stderrs.append(std)\n",
    "                           \n",
    "                        \n",
    "                        parameters['Column'] = columns\n",
    "                        parameters['Slope'] = slopes\n",
    "                        parameters['Intercept'] = intercepts\n",
    "                        parameters['R_Sq'] = rvals\n",
    "                        parameters['P_Val'] = pvals\n",
    "                        parameters['StdErr'] = stderrs\n",
    "\n",
    "                        print(parameters.R_Sq.max())\n",
    "                    \n",
    "                    if parameters['R_Sq'].max() >= 0.95:\n",
    "                        \n",
    "                        print(\"Good curve\")\n",
    "                    \n",
    "                        shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + str(sheet_name))\n",
    "                    \n",
    "                    \n",
    "                    else:\n",
    "                    # Marking bad curve sheet and moving to 'Completed' folder to avoid re-running in the future\n",
    "                    \n",
    "                        print(\"Bad Curve\")\n",
    "                    \n",
    "                        shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + 'x_BAD_CURVE_' +str(sheet_name))\n",
    "\n",
    "                    \n",
    "                    # Adding Sample ID information from bad calibration to appropriate list of re-runs\n",
    "\n",
    "                        for i, row in lab_data.iterrows():\n",
    "                            if row['Type'] == 'O':\n",
    "                                if title == \"URE\":\n",
    "                                    U_Re_Run.append(row['Sample_ID'])\n",
    "                                elif title == \"NIT\":\n",
    "                                    N_Re_Run.append(row['Sample_ID'])\n",
    "                            elif row['Type'] == 'D':\n",
    "                                if title == \"URE\":\n",
    "                                    U_Re_Run.append(row['Sample_ID'])\n",
    "                                elif title == \"NIT\":\n",
    "                                    N_Re_Run.append(row['Sample_ID'])\n",
    "\n",
    "\n",
    "                # If the calibration data is acceptable:                 \n",
    "                                \n",
    "                else: \n",
    "                    \n",
    "                    # Defining which rows contain sample data\n",
    "\n",
    "                    sample_data = lab_data[lab_data.Type != 'C']\n",
    "                    sample_data = sample_data[sample_data.Type != 'B']\n",
    "                    \n",
    "                    \n",
    "                    # Creating new dataframe with only ID & absorbance\n",
    "                    \n",
    "                    sample_data_ab = sample_data[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "\n",
    "                    # Grouping sample data based on unique ID\n",
    "\n",
    "                    sample_data_g = sample_data_ab.groupby('Sample_ID')\n",
    "\n",
    "\n",
    "                    # Merging and creating a new dataframe for original/duplicate variance values (max-min/max)\n",
    "\n",
    "                    sample_data_var = sample_data_ab.merge((abs((sample_data_g.max() - sample_data_g.min())) / (sample_data_g.max())), on='Sample_ID')\n",
    "\n",
    "\n",
    "                    # Create conditional based on variance column\n",
    "\n",
    "                    for i, row in sample_data_var.iterrows():\n",
    "                        if float(row['Absorbance_y']) > 0.1:\n",
    "\n",
    "                            \n",
    "                            # Adding sample ID information to appropriate list if variance is unacceptable\n",
    "                            \n",
    "                            if title == \"URE\":\n",
    "                                U_Re_Run.append(row['Sample_ID'])\n",
    "                            elif title == \"NIT\":\n",
    "                                N_Re_Run.append(row['Sample_ID'])\n",
    "                                \n",
    "\n",
    "                    # Moving working sheet to 'Completed' folder in folder to avoid re-running in the future            \n",
    "                                \n",
    "                    shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + str(sheet_name))\n",
    "\n",
    "            \n",
    "            # Pulling additional parts of name to identify sheet for naming/moving\n",
    "            \n",
    "            set_ = sheet_name.split('_')[1]\n",
    "            title1 = sheet_name.split('_')[3]\n",
    "            title2 = sheet_name.split('_')[4]\n",
    "            titles = (title1, title2)\n",
    "            file_name = ('_').join(titles)\n",
    "            file_name  \n",
    "            \n",
    "\n",
    "            # Creating a conditional for creating new sheets with URE re-runs (if list is not empty)\n",
    "\n",
    "            if U_Re_Run != []:\n",
    "                \n",
    "                \n",
    "                # Prompting user to identify desired set size for re-runs\n",
    "\n",
    "                samp_set = int(input('You have ' + str(len(U_Re_Run)/2) + ' unique samples (not including duplicates) to re-run for Ureides in ' + str(loc) + '. How many of these do you wish to run per set?'))\n",
    "                print(\"Creating \" + str(math.ceil(len(U_Re_Run)/(samp_set*2))) + \" sheets for \" + str(len(U_Re_Run)) + \" total samples.\")\n",
    "\n",
    "                \n",
    "                # Creating dataframe with re-run list\n",
    "                \n",
    "                U_Re_Run = pd.DataFrame(U_Re_Run)\n",
    "\n",
    "                \n",
    "                # Setting a counter to control iterations in while loop\n",
    "                \n",
    "                counter = 0\n",
    "\n",
    "                \n",
    "                # Creating sheets based on provided set size\n",
    "\n",
    "                while counter <= math.ceil(len(U_Re_Run)/(samp_set*2)):\n",
    "\n",
    "                    for i in range(math.ceil(len(U_Re_Run)/(samp_set*2))):\n",
    "\n",
    "                        template2 = U_Re_Run[(i*samp_set*2):((1+i)*samp_set*2)]\n",
    "\n",
    "\n",
    "                        # Inserting rows for blanks and curve data in ureides through a list\n",
    "\n",
    "                        utop = []\n",
    "\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, '2_2')\n",
    "                        utop.insert(0, '2_1')\n",
    "                        utop.insert(0, '1_2')\n",
    "                        utop.insert(0, '1_1')\n",
    "\n",
    "                        \n",
    "                        # Combining utop list and ID information into one dataframe\n",
    "                        \n",
    "                        template2 = pd.concat([pd.DataFrame(utop), template2], ignore_index = True)\n",
    "\n",
    "\n",
    "                        # Creating values for sample type\n",
    "\n",
    "                        seq = cycle(['O', 'D'])\n",
    "\n",
    "                        type_list = ['B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "\n",
    "\n",
    "                        \n",
    "                        # Creating new columns in dataframe and appending corresponding data \n",
    "                        # ... or leaving rows empty for lab to fill in later\n",
    "                        \n",
    "\n",
    "                        template2['Type'] = [next(seq) for i in range(len(template2))]\n",
    "                        \n",
    "                        template2.Type[0:16] = type_list\n",
    "                        \n",
    "                        template2['Sample_Wt(g)'] = ''\n",
    "                        \n",
    "                        template2['Absorbance'] = ''\n",
    "                        \n",
    "                        template2 = template2[['Type', 'Sample_Wt(g)', 0, 'Absorbance']]\n",
    "                        \n",
    "                        template2.columns = ['Type', 'Sample_Wt(g)', 'Sample_ID', 'Absorbance']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # Setting directory as original folder\n",
    "\n",
    "                        glob.os.chdir(datasheets + '/' + str(loc))\n",
    "                        \n",
    "\n",
    "                        # Saving each ureide datasheet with a unique name based on set# \n",
    "                        # ... date is blank for user to change later when sampes are run\n",
    "                        # First letter in name is changed based on number of repetitions\n",
    "                        \n",
    "\n",
    "                        if sheet_name.split('_')[0] == 'A':\n",
    "                            \n",
    "                            template2.to_csv('B_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            \n",
    "                            # User is notified of where to find sheets and what they are named\n",
    "                            \n",
    "                            print('New lab sheets saved as B_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                         \n",
    "                        \n",
    "                        \n",
    "                        elif sheet_name.split('_')[0] == 'B':\n",
    "                            \n",
    "                            template2.to_csv('C_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as C_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'C':\n",
    "                            \n",
    "                            template2.to_csv('D_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as D_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                           \n",
    "                        \n",
    "                        elif sheet_name.split('_')[0] == 'D':\n",
    "                            \n",
    "                            template2.to_csv('E_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as E_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            template2.to_csv('xx_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as xx_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        # Appending counter to reflect loop iterations\n",
    "                        \n",
    "                        counter = counter + 2\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            # Creating a conditional for creating new sheets with NIT re-runs (if list is not empty)\n",
    "            \n",
    "            if N_Re_Run != []:\n",
    "                \n",
    "                \n",
    "                # Prompting user to identify desired set size for re-runs\n",
    "                \n",
    "                samp_set = int(input('You have ' + str(len(N_Re_Run)/2) + ' unique samples (not including duplicates) to re-run for Nitrates in ' + str(loc) + '. How many of these do you wish to run per set?'))\n",
    "                print(\"Creating \" + str(math.ceil(len(N_Re_Run)/(samp_set*2))) + \" sheets for \" + str(len(N_Re_Run)) + \" total samples.\")\n",
    "\n",
    "                \n",
    "                # Creating dataframe with re-run list\n",
    "                \n",
    "                N_Re_Run = pd.DataFrame(N_Re_Run)\n",
    "                \n",
    "                \n",
    "                # Setting a counter to control iterations in while loop\n",
    "\n",
    "                counter = 0\n",
    "                \n",
    "\n",
    "                # Creating sheets based on provided set size\n",
    "\n",
    "                while counter <= math.ceil(len(N_Re_Run)/(samp_set*2)):\n",
    "\n",
    "                    for i in range(math.ceil(len(N_Re_Run)/(samp_set*2))):\n",
    "\n",
    "                        template2 = N_Re_Run[(i*samp_set*2):((1+i)*samp_set*2)]\n",
    "\n",
    "\n",
    "                        # Inserting rows for blanks and curve data in nitrates through a list\n",
    "\n",
    "                        ntop = []\n",
    "\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, '2_2')\n",
    "                        ntop.insert(0, '2_1')\n",
    "                        ntop.insert(0, '1_2')\n",
    "                        ntop.insert(0, '1_1')\n",
    "\n",
    "                        \n",
    "                        # Combining ntop list and ID information into one dataframe\n",
    "                        \n",
    "                        template2 = pd.concat([pd.DataFrame(ntop), template2], ignore_index = True)\n",
    "\n",
    "\n",
    "                        # Creating values for sample type\n",
    "\n",
    "                        seq = cycle(['O', 'D'])\n",
    "\n",
    "                        type_list = ['B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "\n",
    "\n",
    "                        \n",
    "                        # Creating new columns in dataframe and appending corresponding data \n",
    "                        # ... or leaving rows empty for lab to fill in later\n",
    "\n",
    "                        \n",
    "                        template2['Type'] = [next(seq) for i in range(len(template2))]\n",
    "                        \n",
    "                        template2.Type[0:16] = type_list\n",
    "                        \n",
    "                        template2['Sample_Wt(g)'] = ''\n",
    "                        \n",
    "                        template2['Absorbance'] = ''\n",
    "                        \n",
    "                        template2 = template2[['Type', 'Sample_Wt(g)', 0, 'Absorbance']]\n",
    "                        \n",
    "                        template2.columns = ['Type', 'Sample_Wt(g)', 'Sample_ID', 'Absorbance']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # Setting directory as original folder\n",
    "\n",
    "                        glob.os.chdir(datasheets + '/' + str(loc))\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        # Saving each ureide datasheet with a unique name based on set# \n",
    "                        # ... date is blank for user to change later when sampes are run\n",
    "                        # First letter in name is changed based on number of repetitions\n",
    "\n",
    "                        if sheet_name.split('_')[0] == 'A':\n",
    "                            \n",
    "                            template2.to_csv('B_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            \n",
    "                            # User is notified of where to find sheets and what they are named\n",
    "                            \n",
    "                            print('New lab sheets saved as B_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'B':\n",
    "                            \n",
    "                            template2.to_csv('C_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as C_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'C':\n",
    "                            \n",
    "                            template2.to_csv('D_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as D_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'D':\n",
    "                            \n",
    "                            template2.to_csv('E_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as E_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            template2.to_csv('xx_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as xx_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "\n",
    "                            \n",
    "                        # Appending counter to reflect loop iterations    \n",
    "                            \n",
    "                        counter = counter + 2\n",
    "\n",
    "                        \n",
    "                        \n",
    "    \n",
    "    # Continuing to loop through folders if folder is empty and the attempted operations cannot be completed\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
