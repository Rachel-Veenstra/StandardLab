{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_screening Code\n",
    "#### Author: Rachel Veenstra\n",
    "#### Date Created: 04-12-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Setting loop for iterating through files WITHIN folders IN the specified folder\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    \n",
    "    \n",
    "    # Using \"try\" loop in the event that a folder is empty\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        \n",
    "        # Looping through every file in a folder\n",
    "        \n",
    "        for loc in folder:\n",
    "            \n",
    "            \n",
    "            # Identifying working folder\n",
    "            \n",
    "            print(loc)\n",
    "\n",
    "            folder_loc = datasheets + loc\n",
    "\n",
    "            glob.os.chdir(folder_loc)\n",
    "            \n",
    "            \n",
    "            # Grabbing all csv files in specified folder\n",
    "\n",
    "            all_datasheets = glob.glob(folder_loc + \"/*.csv\")\n",
    "            \n",
    "            \n",
    "            # Creating empty lists to append with ID's that fail quality screening\n",
    "\n",
    "            N_Re_Run = []\n",
    "            U_Re_Run = []\n",
    "            \n",
    "            \n",
    "            # Screening each sheet individually\n",
    "\n",
    "            for sheet in all_datasheets:\n",
    "\n",
    "                \n",
    "                # Reading working file as dataframe in pandas\n",
    "                \n",
    "                lab_data = pd.read_csv(sheet)\n",
    "                \n",
    "                \n",
    "                # Pulling parts of name to identify sheet for naming/moving\n",
    "\n",
    "                sheet_name = sheet.split('\\\\')[-1]\n",
    "                title = sheet_name.split('_')[2]\n",
    "            \n",
    "            \n",
    "            \n",
    "### SCREENING FOR PRESENCE OF DATA            \n",
    "            \n",
    "    \n",
    "    \n",
    "                # Checking for data - skipping remainder of code (breaking loop) if there is no data\n",
    "\n",
    "                if np.isnan(lab_data.Absorbance[4]):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                # Continuing if data is found\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # Identifying sheet\n",
    "                    \n",
    "                    print(sheet)\n",
    "                    \n",
    "\n",
    "                    \n",
    "### SCREENING BLANKS                        \n",
    "                    \n",
    "    \n",
    "    \n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "                    \n",
    "                    blanks_abs = []\n",
    "\n",
    "                    \n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "                    \n",
    "                    for n in range(len(lab_data)):\n",
    "                        if lab_data.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(lab_data.Absorbance[n]))\n",
    "                            \n",
    "                  \n",
    "                    # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "                            \n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "                    \n",
    "                    \n",
    "                    # If the list of acceptable blanks has fewer than three values, set must be repeated\n",
    "                    \n",
    "                    if len(good_blanks) <= 2 :\n",
    "                        \n",
    "                        \n",
    "                        # Marking bad blanks sheet and moving to 'Completed' folder to avoid re-running in the future\n",
    "                    \n",
    "                        #print(\"Bad Blanks\")\n",
    "                    \n",
    "                        shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + 'x_BAD_BLANKS_' +str(sheet_name))\n",
    "\n",
    "                    \n",
    "                        # Adding Sample ID information from bad calibration to appropriate list of re-runs\n",
    "\n",
    "                        for i, row in lab_data.iterrows():\n",
    "                            if row['Type'] == 'O':\n",
    "                                if title == \"URE\":\n",
    "                                    U_Re_Run.append(row['Sample_ID'])\n",
    "                                elif title == \"NIT\":\n",
    "                                    N_Re_Run.append(row['Sample_ID'])\n",
    "                            elif row['Type'] == 'D':\n",
    "                                if title == \"URE\":\n",
    "                                    U_Re_Run.append(row['Sample_ID'])\n",
    "                                elif title == \"NIT\":\n",
    "                                    N_Re_Run.append(row['Sample_ID'])\n",
    "                        \n",
    "                        \n",
    "### SCREENING CURVES\n",
    "\n",
    "## code will check if curve can be \n",
    "## adjusted to produce and acceptable r^2\n",
    "\n",
    "\n",
    "\n",
    "                    # If the list of acceptable blanks has three good values, set is acceptable\n",
    "                        \n",
    "                    else:\n",
    "                    \n",
    "                        # Creating empty lists to append with curve information\n",
    "\n",
    "                        curve_absorbance = []\n",
    "                        curve_concentration = []\n",
    "\n",
    "\n",
    "                        # Identifying standard absorbances based on 'Type' column\n",
    "\n",
    "                        for n in range(len(lab_data)):\n",
    "                            if lab_data.Type[n] == 'C':\n",
    "\n",
    "\n",
    "                                # Appending calibration data to appropriate list for curve analysis\n",
    "\n",
    "                                curve_absorbance.append(float(lab_data.Absorbance[n]))\n",
    "                                curve_concentration.append(float(lab_data.Sample_ID[n]))\n",
    "\n",
    "\n",
    "                        # Calculating r^2 value for two calibration data lists with lin.regress module\n",
    "\n",
    "                        slope, intercept, r_value, p_value, std_err = stats.linregress(curve_absorbance, curve_concentration)\n",
    "\n",
    "\n",
    "                        # Creating conditional for screening based on r^2 value... using a matrix to calculate optional r^2 values based\n",
    "                        # on removal of one curve point\n",
    "\n",
    "                        if r_value**2 < 0.95:\n",
    "\n",
    "                            # Creating pandas dataframe for analysis\n",
    "\n",
    "                            columns = [['Conc', 'Abs']]\n",
    "\n",
    "                            curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                            curve['Conc'] = curve_concentration\n",
    "                            curve['Abs'] = curve_absorbance\n",
    "\n",
    "\n",
    "                            # Defining the size of the possible removal matrix\n",
    "\n",
    "                            points = len(curve_concentration) # Total number of datapoints\n",
    "\n",
    "\n",
    "                            # Creating a matrix via a numpy array \n",
    "\n",
    "                            array = np.identity(points)\n",
    "\n",
    "\n",
    "                            # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                            for i in range(array.shape[1]):\n",
    "\n",
    "                                curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                            # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                            for i in range(1,points):\n",
    "\n",
    "                                array = np.identity(i)\n",
    "                                array = np.vstack([array, [1]*i])\n",
    "\n",
    "                                if array.shape[0] != 12:\n",
    "                                    for j in range(12 - array.shape[0]):\n",
    "                                        array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                    for k in range(array.shape[1]):\n",
    "\n",
    "                                        curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                            # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "\n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                            ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                            #print(parameters['R_Sq'].max())\n",
    "                            #print(parameters)\n",
    "\n",
    "\n",
    "                            # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                            # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                            # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                            if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                                # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                                columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                                columns = []\n",
    "                                slopes = []\n",
    "                                intercepts = []\n",
    "                                rvals = []\n",
    "                                pvals = []\n",
    "                                stderrs = []\n",
    "\n",
    "                                parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                                # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                                for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                    columns.append(column)\n",
    "\n",
    "\n",
    "                                    # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                    count = 0\n",
    "                                    conc = []\n",
    "                                    absorb = []\n",
    "\n",
    "\n",
    "                                    # Running conditional by row in column\n",
    "\n",
    "                                    for i in curve[column]: \n",
    "\n",
    "\n",
    "                                        # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                        if i < 1:\n",
    "                                            conc.append(curve.iloc[count,0])\n",
    "                                            absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                        # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                        count = count + 1\n",
    "\n",
    "\n",
    "                                    # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                    slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                    slopes.append(slope)\n",
    "                                    intercepts.append(inter)\n",
    "                                    rvals.append(r_val**2)\n",
    "                                    pvals.append(p_val)\n",
    "                                    stderrs.append(std)\n",
    "\n",
    "                                # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                                parameters['Column'] = columns\n",
    "                                parameters['Slope'] = slopes\n",
    "                                parameters['Intercept'] = intercepts\n",
    "                                parameters['R_Sq'] = rvals\n",
    "                                parameters['P_Val'] = pvals\n",
    "                                parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                                # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                                print(parameters.R_Sq.max())\n",
    "\n",
    "\n",
    "\n",
    "                            # If the curve can be improved to an acceptable r^2 by removing one or two points, the curve \"passes\" screening\n",
    "\n",
    "                            if parameters['R_Sq'].max() >= 0.95:\n",
    "\n",
    "                                print(\"Good curve\")\n",
    "\n",
    "\n",
    "                                # Sheet is moved to the 'Completed' folder to avoid re-running in the future\n",
    "\n",
    "                                shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + str(sheet_name))\n",
    "\n",
    "\n",
    "\n",
    "                            # If the curve cannot be improved after removing two points, the set needs to be completely re-run\n",
    "\n",
    "                            else:\n",
    "\n",
    "\n",
    "                            # Marking bad curve sheet and moving to 'Completed' folder to avoid re-running in the future\n",
    "\n",
    "                                print(\"Bad Curve\")\n",
    "\n",
    "                                shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + 'x_BAD_CURVE_' +str(sheet_name))\n",
    "\n",
    "\n",
    "                            # Adding Sample ID information from bad calibration to appropriate list of re-runs\n",
    "\n",
    "                                for i, row in lab_data.iterrows():\n",
    "                                    if row['Type'] == 'O':\n",
    "                                        if title == \"URE\":\n",
    "                                            U_Re_Run.append(row['Sample_ID'])\n",
    "                                        elif title == \"NIT\":\n",
    "                                            N_Re_Run.append(row['Sample_ID'])\n",
    "                                    elif row['Type'] == 'D':\n",
    "                                        if title == \"URE\":\n",
    "                                            U_Re_Run.append(row['Sample_ID'])\n",
    "                                        elif title == \"NIT\":\n",
    "                                            N_Re_Run.append(row['Sample_ID'])\n",
    "\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "### SCREENING FOR SAMPLE ORIGINAL/DUPLICATE VARIATION                                            \n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "                        # If the calibration data is acceptable:                 \n",
    "\n",
    "                        else: \n",
    "\n",
    "                            # Defining which rows contain sample data\n",
    "\n",
    "                            sample_data = lab_data[lab_data.Type != 'C']\n",
    "                            sample_data = sample_data[sample_data.Type != 'B']\n",
    "\n",
    "\n",
    "                            # Creating new dataframe with only ID & absorbance\n",
    "\n",
    "                            sample_data_ab = sample_data[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "\n",
    "                            # Grouping sample data based on unique ID\n",
    "\n",
    "                            sample_data_g = sample_data_ab.groupby('Sample_ID')\n",
    "\n",
    "\n",
    "                            # Merging and creating a new dataframe for original/duplicate variance values (max-min/max)\n",
    "\n",
    "                            sample_data_var = sample_data_ab.merge((abs((sample_data_g.max() - sample_data_g.min())) / (sample_data_g.max())), on='Sample_ID')\n",
    "\n",
    "\n",
    "                            # Create conditional based on variance column\n",
    "\n",
    "                            for i, row in sample_data_var.iterrows():\n",
    "                                if float(row['Absorbance_y']) > 0.1:\n",
    "\n",
    "\n",
    "                                    # Adding sample ID information to appropriate list if variance is unacceptable\n",
    "\n",
    "                                    if title == \"URE\":\n",
    "                                        U_Re_Run.append(row['Sample_ID'])\n",
    "                                    elif title == \"NIT\":\n",
    "                                        N_Re_Run.append(row['Sample_ID'])\n",
    "\n",
    "\n",
    "                            # Moving working sheet to 'Completed' folder in folder to avoid re-running in the future            \n",
    "\n",
    "                            shutil.move(sheet, '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/' + loc + '/Completed/' + str(sheet_name))\n",
    "\n",
    "            \n",
    "            # Pulling additional parts of name to identify sheet for naming/moving\n",
    "            \n",
    "            set_ = sheet_name.split('_')[1]\n",
    "            title1 = sheet_name.split('_')[3]\n",
    "            title2 = sheet_name.split('_')[4]\n",
    "            titles = (title1, title2)\n",
    "            file_name = ('_').join(titles)\n",
    "            file_name  \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "### CREATING NEW SHEETS WITH VALUES FROM ANY UNACCEPTABLE LEVELS FROM NESTED SCREENINGS            \n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "            # Creating a conditional for creating new sheets with URE re-runs (if list is not empty)\n",
    "\n",
    "            if U_Re_Run != []:\n",
    "                \n",
    "                \n",
    "                # Prompting user to identify desired set size for re-runs\n",
    "\n",
    "                samp_set = int(input('You have ' + str(len(U_Re_Run)/2) + ' unique samples (not including duplicates) to re-run for Ureides in ' + str(loc) + '. How many of these do you wish to run per set?'))\n",
    "                print(\"Creating \" + str(math.ceil(len(U_Re_Run)/(samp_set*2))) + \" sheets for \" + str(len(U_Re_Run)) + \" total samples.\")\n",
    "\n",
    "                \n",
    "                # Creating dataframe with re-run list\n",
    "                \n",
    "                U_Re_Run = pd.DataFrame(U_Re_Run)\n",
    "\n",
    "                \n",
    "                # Setting a counter to control iterations in while loop\n",
    "                \n",
    "                counter = 0\n",
    "\n",
    "                \n",
    "                # Creating sheets based on provided set size\n",
    "\n",
    "                while counter <= math.ceil(len(U_Re_Run)/(samp_set*2)):\n",
    "\n",
    "                    for i in range(math.ceil(len(U_Re_Run)/(samp_set*2))):\n",
    "\n",
    "                        template2 = U_Re_Run[(i*samp_set*2):((1+i)*samp_set*2)]\n",
    "\n",
    "\n",
    "                        # Inserting rows for blanks and curve data in ureides through a list\n",
    "\n",
    "                        utop = []\n",
    "\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 4396.660764)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 1099.165191)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 549.5825955)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, 0.00)\n",
    "                        utop.insert(0, '2_2')\n",
    "                        utop.insert(0, '2_1')\n",
    "                        utop.insert(0, '1_2')\n",
    "                        utop.insert(0, '1_1')\n",
    "\n",
    "                        \n",
    "                        # Combining utop list and ID information into one dataframe\n",
    "                        \n",
    "                        template2 = pd.concat([pd.DataFrame(utop), template2], ignore_index = True)\n",
    "\n",
    "\n",
    "                        # Creating values for sample type\n",
    "\n",
    "                        seq = cycle(['O', 'D'])\n",
    "\n",
    "                        type_list = ['B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "\n",
    "\n",
    "                        \n",
    "                        # Creating new columns in dataframe and appending corresponding data \n",
    "                        # ... or leaving rows empty for lab to fill in later\n",
    "                        \n",
    "\n",
    "                        template2['Type'] = [next(seq) for i in range(len(template2))]\n",
    "                        \n",
    "                        template2.Type[0:16] = type_list\n",
    "                        \n",
    "                        template2['Sample_Wt(g)'] = ''\n",
    "                        \n",
    "                        template2['Absorbance'] = ''\n",
    "                        \n",
    "                        template2 = template2[['Type', 'Sample_Wt(g)', 0, 'Absorbance']]\n",
    "                        \n",
    "                        template2.columns = ['Type', 'Sample_Wt(g)', 'Sample_ID', 'Absorbance']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # Setting directory as original folder\n",
    "\n",
    "                        glob.os.chdir(datasheets + '/' + str(loc))\n",
    "                        \n",
    "\n",
    "                        # Saving each ureide datasheet with a unique name based on set# \n",
    "                        # ... date is blank for user to change later when sampes are run\n",
    "                        # First letter in name is changed based on number of repetitions\n",
    "                        \n",
    "\n",
    "                        if sheet_name.split('_')[0] == 'A':\n",
    "                            \n",
    "                            template2.to_csv('B_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            \n",
    "                            # User is notified of where to find sheets and what they are named\n",
    "                            \n",
    "                            print('New lab sheets saved as B_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                         \n",
    "                        \n",
    "                        \n",
    "                        elif sheet_name.split('_')[0] == 'B':\n",
    "                            \n",
    "                            template2.to_csv('C_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as C_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'C':\n",
    "                            \n",
    "                            template2.to_csv('D_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as D_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                           \n",
    "                        \n",
    "                        elif sheet_name.split('_')[0] == 'D':\n",
    "                            \n",
    "                            template2.to_csv('E_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as E_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            template2.to_csv('xx_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as xx_' + str(i+1) + '_URE_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        # Appending counter to reflect loop iterations\n",
    "                        \n",
    "                        counter = counter + 2\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            # Creating a conditional for creating new sheets with NIT re-runs (if list is not empty)\n",
    "            \n",
    "            if N_Re_Run != []:\n",
    "                \n",
    "                \n",
    "                # Prompting user to identify desired set size for re-runs\n",
    "                \n",
    "                samp_set = int(input('You have ' + str(len(N_Re_Run)/2) + ' unique samples (not including duplicates) to re-run for Nitrates in ' + str(loc) + '. How many of these do you wish to run per set?'))\n",
    "                print(\"Creating \" + str(math.ceil(len(N_Re_Run)/(samp_set*2))) + \" sheets for \" + str(len(N_Re_Run)) + \" total samples.\")\n",
    "\n",
    "                \n",
    "                # Creating dataframe with re-run list\n",
    "                \n",
    "                N_Re_Run = pd.DataFrame(N_Re_Run)\n",
    "                \n",
    "                \n",
    "                # Setting a counter to control iterations in while loop\n",
    "\n",
    "                counter = 0\n",
    "                \n",
    "\n",
    "                # Creating sheets based on provided set size\n",
    "\n",
    "                while counter <= math.ceil(len(N_Re_Run)/(samp_set*2)):\n",
    "\n",
    "                    for i in range(math.ceil(len(N_Re_Run)/(samp_set*2))):\n",
    "\n",
    "                        template2 = N_Re_Run[(i*samp_set*2):((1+i)*samp_set*2)]\n",
    "\n",
    "\n",
    "                        # Inserting rows for blanks and curve data in nitrates through a list\n",
    "\n",
    "                        ntop = []\n",
    "\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 4500.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 3000.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 1500.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, 0.00)\n",
    "                        ntop.insert(0, '2_2')\n",
    "                        ntop.insert(0, '2_1')\n",
    "                        ntop.insert(0, '1_2')\n",
    "                        ntop.insert(0, '1_1')\n",
    "\n",
    "                        \n",
    "                        # Combining ntop list and ID information into one dataframe\n",
    "                        \n",
    "                        template2 = pd.concat([pd.DataFrame(ntop), template2], ignore_index = True)\n",
    "\n",
    "\n",
    "                        # Creating values for sample type\n",
    "\n",
    "                        seq = cycle(['O', 'D'])\n",
    "\n",
    "                        type_list = ['B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "\n",
    "\n",
    "                        \n",
    "                        # Creating new columns in dataframe and appending corresponding data \n",
    "                        # ... or leaving rows empty for lab to fill in later\n",
    "\n",
    "                        \n",
    "                        template2['Type'] = [next(seq) for i in range(len(template2))]\n",
    "                        \n",
    "                        template2.Type[0:16] = type_list\n",
    "                        \n",
    "                        template2['Sample_Wt(g)'] = ''\n",
    "                        \n",
    "                        template2['Absorbance'] = ''\n",
    "                        \n",
    "                        template2 = template2[['Type', 'Sample_Wt(g)', 0, 'Absorbance']]\n",
    "                        \n",
    "                        template2.columns = ['Type', 'Sample_Wt(g)', 'Sample_ID', 'Absorbance']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # Setting directory as original folder\n",
    "\n",
    "                        glob.os.chdir(datasheets + '/' + str(loc))\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        # Saving each ureide datasheet with a unique name based on set# \n",
    "                        # ... date is blank for user to change later when sampes are run\n",
    "                        # First letter in name is changed based on number of repetitions\n",
    "\n",
    "                        if sheet_name.split('_')[0] == 'A':\n",
    "                            \n",
    "                            template2.to_csv('B_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            \n",
    "                            # User is notified of where to find sheets and what they are named\n",
    "                            \n",
    "                            print('New lab sheets saved as B_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'B':\n",
    "                            \n",
    "                            template2.to_csv('C_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as C_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'C':\n",
    "                            \n",
    "                            template2.to_csv('D_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as D_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        elif sheet_name.split('_')[0] == 'D':\n",
    "                            \n",
    "                            template2.to_csv('E_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as E_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            template2.to_csv('xx_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv', index=False)\n",
    "                            \n",
    "                            print('New lab sheets saved as xx_' + str(i+1) + '_NIT_' + file_name + '_00_00_00.csv')\n",
    "                            \n",
    "\n",
    "                            \n",
    "                        # Appending counter to reflect loop iterations    \n",
    "                            \n",
    "                        counter = counter + 2\n",
    "\n",
    "                        \n",
    "                        \n",
    "    \n",
    "    # Continuing to loop through folders if folder is empty and the attempted operations cannot be completed\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
