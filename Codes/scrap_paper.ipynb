{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS_ASH_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_1_NIT_MS_ASH_LI_12_17_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_2_NIT_MS_ASH_LI_12_17_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_3_NIT_MS_ASH_LI_12_18_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_4_NIT_MS_ASH_LI_12_18_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_5_NIT_MS_ASH_LI_12_19_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_6_NIT_MS_ASH_LI_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_8_NIT_MS_ASH_LI_12_20_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_2_NIT_MS_ASH_LI_01_03_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_3_NIT_MS_ASH_LI_01_04_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_5_NIT_MS_ASH_LI_01_04_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_7_NIT_MS_ASH_LI_12_20_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_1_URE_MS_ASH_LI_11_15_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_2_URE_MS_ASH_LI_11_16_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_3_URE_MS_ASH_LI_11_19_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_5_URE_MS_ASH_LI_11_20_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_6_URE_MS_ASH_LI_11_21_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_7_URE_MS_ASH_LI_12_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_9_URE_MS_ASH_LI_12_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_1_URE_MS_ASH_LI_12_10_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_6_URE_MS_ASH_LI_01_29_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_8_URE_MS_ASH_LI_11_20_18.csv\n",
      "MS_GH_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_15_NIT_MS_GH_LI_10_04_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_16_NIT_MS_GH_LI_10_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_17_NIT_MS_GH_LI_10_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_1_NIT_MS_GH_LI_07_12_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_3_NIT_MS_GH_LI_07_13_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_8_NIT_MS_GH_LI_07_09_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_9_NIT_MS_GH_LI_07_10_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_2_NIT_MS_GH_LI_07_16_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_7_NIT_MS_GH_LI_10_08_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_8_NIT_MS_GH_LI_10_08_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_15_URE_MS_GH_LI_10_01_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_16_URE_MS_GH_LI_10_02_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_17_URE_MS_GH_LI_10_02_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_1_URE_MS_GH_LI_06_25_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_2_URE_MS_GH_LI_06_28_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_3_URE_MS_GH_LI_07_02_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_4_URE_MS_GH_LI_07_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_7_URE_MS_GH_LI_07_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_8_URE_MS_GH_LI_07_09_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_9_URE_MS_GH_LI_07_10_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_5_URE_MS_GH_LI_07_27_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_6_URE_MS_GH_LI_10_03_18.csv\n",
      "MS_OTT_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_1_NIT_MS_OTT_LI_01_07_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_2_NIT_MS_OTT_LI_01_08_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_3_NIT_MS_OTT_LI_01_09_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_4_NIT_MS_OTT_LI_01_09_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_5_NIT_MS_OTT_LI_01_10_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_10_NIT_MS_OTT_LI_01_15_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_11_NIT_MS_OTT_LI_01_15_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_12_NIT_MS_OTT_LI_01_16_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_13_NIT_MS_OTT_LI_01_18_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_14_NIT_MS_OTT_LI_01_15_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_8_NIT_MS_OTT_LI_01_11_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_9_NIT_MS_OTT_LI_01_14_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\C_8_NIT_MS_OTT_LI_01_11_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_1_URE_MS_OTT_LI_11_21_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_3_URE_MS_OTT_LI_11_27_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_4_URE_MS_OTT_LI_11_28_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_5_URE_MS_OTT_LI_11_28_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_2_URE_MS_OTT_LI_12_11_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\B_7_URE_MS_OTT_LI_12_12_18.csv\n",
      "RAU COMPLETED\n",
      "LMR_IA_USB\n",
      "LMR_IN_USB\n",
      "LMR_MN_USB\n",
      "LMR_SD_USB\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Pulling data to navigate to completed folders in each topic folder\n",
    "\n",
    "topic_folders = []\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    for loc in folder:\n",
    "        topic_folders.append(loc)\n",
    "        \n",
    "topic_folders = [x for x in topic_folders if x != 'Completed']\n",
    "topic_folders\n",
    "\n",
    "for i in topic_folders:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        print(i)\n",
    "\n",
    "        folder_name = str(i)\n",
    "        \n",
    "        location = \"Student_Lists/Completed/\"\n",
    "\n",
    "        sheet = i + '.csv'\n",
    "\n",
    "        id_file = '/Users/' + user + '/Desktop/Coding/StandardLab/' + location\n",
    "\n",
    "        glob.os.chdir(id_file)\n",
    "\n",
    "        u_id_list = pd.read_csv(sheet, header=None)\n",
    "\n",
    "        u_id_list.columns = ['Sample_ID']\n",
    "\n",
    "        ureides = u_id_list\n",
    "        \n",
    "        n_id_list = pd.read_csv(sheet, header=None)\n",
    "\n",
    "        n_id_list.columns = ['Sample_ID']\n",
    "        \n",
    "        nitrates = n_id_list\n",
    "        \n",
    "        screened_data = datasheets + i + '/Completed'\n",
    "\n",
    "        glob.os.chdir(screened_data)\n",
    "\n",
    "        alldata = glob.glob(screened_data + \"/*.csv\")\n",
    "\n",
    "        for loc in alldata:\n",
    "\n",
    "            analysis = (loc.split('_')[-7])\n",
    "            flag = (loc.split('_')[-11])\n",
    "            name = (loc.split('\\\\')[-1])\n",
    "\n",
    "            if flag != 'BAD':\n",
    "\n",
    "                if analysis == \"NIT\":\n",
    "\n",
    "                    var_id = []\n",
    "                    nit_id = []\n",
    "                    nit_conc = []\n",
    "\n",
    "                    print(loc)\n",
    "                    DF = pd.read_csv(loc)\n",
    "                    #print(DF)\n",
    "\n",
    "                    nit_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                    nit_g = nit_df.groupby('Sample_ID')\n",
    "\n",
    "                    nit_final=nit_df.merge(nit_g.mean(),on='Sample_ID')\n",
    "\n",
    "                    nit_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "\n",
    "                    # Marking values with high variance\n",
    "\n",
    "                    sample_data_var = nit_df.merge((abs((nit_g.max() - nit_g.min())) / (nit_g.max())), on='Sample_ID')\n",
    "\n",
    "                    sample_data_var['Type'] = DF['Type']\n",
    "\n",
    "                    for i, row in sample_data_var.iterrows():\n",
    "\n",
    "                        if row['Type'] == \"O\":\n",
    "\n",
    "                            if float(row['Absorbance_y']) > 0.1:\n",
    "                                var_id.append('x_')\n",
    "                            else:\n",
    "                                var_id.append('')\n",
    "\n",
    "                    nit_final['Type'] = DF['Type']\n",
    "\n",
    "                    nit_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                    nit_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "\n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "\n",
    "                    blanks_abs = []\n",
    "\n",
    "\n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "\n",
    "                    for n in range(len(nit_final)):\n",
    "                        if nit_final.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(nit_final.Each[n]))\n",
    "\n",
    "\n",
    "                        # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "\n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "\n",
    "                    blank_val = np.mean(good_blanks)\n",
    "\n",
    "                    c=[]\n",
    "                    e=[]\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'C':\n",
    "\n",
    "                            c.append(float(row['Sample_ID']))\n",
    "                            e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                    slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "\n",
    "                    if r_value**2 < 0.95:\n",
    "\n",
    "                            # Creating pandas dataframe for analysis\n",
    "\n",
    "                            columns = [['Conc', 'Abs']]\n",
    "\n",
    "                            curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                            curve['Conc'] = c\n",
    "                            curve['Abs'] = e\n",
    "\n",
    "\n",
    "                            # Defining the size of the possible removal matrix\n",
    "\n",
    "                            points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                            # Creating a matrix via a numpy array \n",
    "\n",
    "                            array = np.identity(points)\n",
    "\n",
    "\n",
    "                            # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                            for i in range(array.shape[1]):\n",
    "\n",
    "                                curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                            # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                            for i in range(1,points):\n",
    "\n",
    "                                array = np.identity(i)\n",
    "                                array = np.vstack([array, [1]*i])\n",
    "\n",
    "                                if array.shape[0] != 12:\n",
    "                                    for j in range(12 - array.shape[0]):\n",
    "                                        array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                    for k in range(array.shape[1]):\n",
    "\n",
    "                                        curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                            # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "\n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                            ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                            #print(parameters['R_Sq'].max())\n",
    "                            #print(parameters)\n",
    "\n",
    "\n",
    "                            # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                            # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                            # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                            if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                                # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                                columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                                columns = []\n",
    "                                slopes = []\n",
    "                                intercepts = []\n",
    "                                rvals = []\n",
    "                                pvals = []\n",
    "                                stderrs = []\n",
    "\n",
    "                                parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                                # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                                for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                    columns.append(column)\n",
    "\n",
    "\n",
    "                                    # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                    count = 0\n",
    "                                    conc = []\n",
    "                                    absorb = []\n",
    "\n",
    "\n",
    "                                    # Running conditional by row in column\n",
    "\n",
    "                                    for i in curve[column]: \n",
    "\n",
    "\n",
    "                                        # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                        if i < 1:\n",
    "                                            conc.append(curve.iloc[count,0])\n",
    "                                            absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                        # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                        count = count + 1\n",
    "\n",
    "\n",
    "                                    # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                    slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                    slopes.append(slope)\n",
    "                                    intercepts.append(inter)\n",
    "                                    rvals.append(r_val**2)\n",
    "                                    pvals.append(p_val)\n",
    "                                    stderrs.append(std)\n",
    "\n",
    "                                # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                                parameters['Column'] = columns\n",
    "                                parameters['Slope'] = slopes\n",
    "                                parameters['Intercept'] = intercepts\n",
    "                                parameters['R_Sq'] = rvals\n",
    "                                parameters['P_Val'] = pvals\n",
    "                                parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                            # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                            #print(parameters.R_Sq.max())\n",
    "\n",
    "                    nconc = []\n",
    "                    nit_conc_var = []\n",
    "\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                        nconc.append(((row['Mean'] - blank_val)*slope + intercept)/((row['Sample_Wt(g)']*1000/7.5)))\n",
    "\n",
    "                    nit_final['Sample_Conc(micrmol/g)'] = nconc\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'O':\n",
    "\n",
    "                            nit_id.append(row['Sample_ID'])\n",
    "                            nit_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "\n",
    "                    for i in range(len(nit_conc)):\n",
    "                        nit_conc_var.append(str(var_id[i]) + str(nit_conc[i]))       \n",
    "\n",
    "\n",
    "                    ncolumns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                    ndata = pd.DataFrame(columns = ncolumns)\n",
    "\n",
    "                    ndata['Sample_ID'] = nit_id\n",
    "                    ndata['Conc'] = nit_conc_var\n",
    "\n",
    "                    final_nitrates = pd.merge(nitrates, ndata, on='Sample_ID', how = 'left')\n",
    "\n",
    "                    complete_nitrates = nitrates\n",
    "\n",
    "                    complete_nitrates[str(name)] = final_nitrates['Conc']\n",
    "\n",
    "        \n",
    "        \n",
    "        for loc in alldata:\n",
    "\n",
    "            analysis = (loc.split('_')[-7])\n",
    "            flag = (loc.split('_')[-11])\n",
    "            name = (loc.split('\\\\')[-1])\n",
    "\n",
    "            if flag != 'BAD':\n",
    "        \n",
    "                if analysis == \"URE\":\n",
    "        \n",
    "                    var_id = []\n",
    "                    ure_id = []\n",
    "                    ure_conc = []\n",
    "\n",
    "                    print(loc)\n",
    "                    DF = pd.read_csv(loc)\n",
    "                    #print(DF)\n",
    "\n",
    "                    ure_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                    ure_g = ure_df.groupby('Sample_ID')\n",
    "\n",
    "                    ure_final = ure_df.merge(ure_g.mean(),on='Sample_ID')\n",
    "\n",
    "                    ure_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "                    # Marking values with high variance\n",
    "\n",
    "                    sample_data_var = ure_df.merge((abs((ure_g.max() - ure_g.min())) / (ure_g.max())), on='Sample_ID')\n",
    "\n",
    "                    sample_data_var['Type'] = DF['Type']\n",
    "\n",
    "                    for i, row in sample_data_var.iterrows():\n",
    "\n",
    "                        if row['Type'] == \"O\":\n",
    "\n",
    "                            if float(row['Absorbance_y']) > 0.1:\n",
    "                                var_id.append('x_')\n",
    "                            else:\n",
    "                                var_id.append('')\n",
    "                  \n",
    "                    ure_final['Type'] = DF['Type']\n",
    "\n",
    "                    ure_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                    ure_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "\n",
    "\n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "\n",
    "                    blanks_abs = []\n",
    "\n",
    "\n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "\n",
    "                    for n in range(len(ure_final)):\n",
    "                        if ure_final.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(ure_final.Each[n]))\n",
    "\n",
    "\n",
    "                        # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "\n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "\n",
    "                    blank_val = np.mean(good_blanks)\n",
    "\n",
    "                    c=[]\n",
    "                    e=[]\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'C':\n",
    "\n",
    "                            c.append(float(row['Sample_ID']))\n",
    "                            e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                    slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "\n",
    "                    if r_value**2 < 0.95:\n",
    "\n",
    "                        # Creating pandas dataframe for analysis\n",
    "\n",
    "                        columns = [['Conc', 'Abs']]\n",
    "\n",
    "                        curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                        curve['Conc'] = c\n",
    "                        curve['Abs'] = e\n",
    "\n",
    "\n",
    "                        # Defining the size of the possible removal matrix\n",
    "\n",
    "                        points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                        # Creating a matrix via a numpy array \n",
    "\n",
    "                        array = np.identity(points)\n",
    "\n",
    "\n",
    "                        # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                        for i in range(array.shape[1]):\n",
    "\n",
    "                            curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                        # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                        for i in range(1,points):\n",
    "\n",
    "                            array = np.identity(i)\n",
    "                            array = np.vstack([array, [1]*i])\n",
    "\n",
    "                            if array.shape[0] != 12:\n",
    "                                for j in range(12 - array.shape[0]):\n",
    "                                    array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                for k in range(array.shape[1]):\n",
    "\n",
    "                                    curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                        # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                        columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                        columns = []\n",
    "                        slopes = []\n",
    "                        intercepts = []\n",
    "                        rvals = []\n",
    "                        pvals = []\n",
    "                        stderrs = []\n",
    "\n",
    "                        parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                        for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                            columns.append(column)\n",
    "\n",
    "\n",
    "                            # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                            count = 0\n",
    "                            conc = []\n",
    "                            absorb = []\n",
    "\n",
    "\n",
    "                            # Running conditional by row in column\n",
    "\n",
    "                            for i in curve[column]: \n",
    "\n",
    "\n",
    "                                # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                if i < 1:\n",
    "                                    conc.append(curve.iloc[count,0])\n",
    "                                    absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                count = count + 1\n",
    "\n",
    "\n",
    "                            # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                            slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                            slopes.append(slope)\n",
    "                            intercepts.append(inter)\n",
    "                            rvals.append(r_val**2)\n",
    "                            pvals.append(p_val)\n",
    "                            stderrs.append(std)\n",
    "\n",
    "\n",
    "                        # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                        parameters['Column'] = columns\n",
    "                        parameters['Slope'] = slopes\n",
    "                        parameters['Intercept'] = intercepts\n",
    "                        parameters['R_Sq'] = rvals\n",
    "                        parameters['P_Val'] = pvals\n",
    "                        parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                        #print(parameters['R_Sq'].max())\n",
    "                        #print(parameters)\n",
    "\n",
    "\n",
    "                        # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                        # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                        # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                        if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                            # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "\n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                        #print(parameters.R_Sq.max())\n",
    "\n",
    "                    conc = []\n",
    "                    ure_conc_var = []\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                        conc.append((((row['Mean'] - blank_val)*slope + intercept)/((row['Sample_Wt(g)']*1000/7.5)))*4)\n",
    "\n",
    "                    ure_final['Sample_Conc(micrmol/g)'] = conc\n",
    "\n",
    "\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                        if row['Type'] == 'O':\n",
    "\n",
    "                            ure_id.append(row['Sample_ID'])\n",
    "                            ure_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "                    for i in range(len(ure_conc)):\n",
    "                        ure_conc_var.append(str(var_id[i]) + str(ure_conc[i]))\n",
    "\n",
    "                    columns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                    udata = pd.DataFrame(columns = columns)\n",
    "\n",
    "                    udata['Sample_ID'] = ure_id\n",
    "                    udata['Conc'] = ure_conc_var \n",
    "\n",
    "                    final_ureides = pd.merge(ureides, udata, on='Sample_ID', how = 'left')  \n",
    "\n",
    "                    complete_ureides = ureides\n",
    "\n",
    "                    complete_ureides[str(name)] = final_ureides['Conc']\n",
    "                \n",
    "        save_loc = '/Users/' + user + '/Desktop/Coding/StandardLab/Results/'\n",
    "\n",
    "        glob.os.chdir(save_loc)\n",
    "        \n",
    "        complete_ureides.to_csv('Results_URE_' + folder_name + '.csv', index=False)\n",
    "        complete_nitrates.to_csv('Results_NIT_' + folder_name + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "        ## BUG AS OF 4-12-19 .... BOTH FILES SAVED ARE IDENTICAL ... SOMEHOW FILES ARE BEING OVREWRITTEN? PROBABLY A NESTING ISSUE.\n",
    "        \n",
    "        \n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR_USB\n",
      "RV_CTS\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/RV_CTS\\A_1_URE_RV_CTS_00_00_00.csv\n",
      "oops\n",
      "USB_Indiana\n",
      "USB_Iowa\n",
      "USB_Minnesota\n",
      "USB_South_Dakota\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Setting loop for iterating through files WITHIN folders IN the specified folder\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    \n",
    "    \n",
    "    # Using \"try\" loop in the event that a folder is empty\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        \n",
    "        # Looping through every file in a folder\n",
    "        \n",
    "        for loc in folder:\n",
    "            \n",
    "            \n",
    "            # Identifying working folder\n",
    "            \n",
    "            print(loc)\n",
    "\n",
    "            folder_loc = datasheets + loc\n",
    "\n",
    "            glob.os.chdir(folder_loc)\n",
    "            \n",
    "            \n",
    "            # Grabbing all csv files in specified folder\n",
    "\n",
    "            all_datasheets = glob.glob(folder_loc + \"/*.csv\")\n",
    "            \n",
    "            \n",
    "            # Creating empty lists to append with ID's that fail quality screening\n",
    "\n",
    "            N_Re_Run = []\n",
    "            U_Re_Run = []\n",
    "            \n",
    "            \n",
    "            # Screening each sheet individually\n",
    "\n",
    "            for sheet in all_datasheets:\n",
    "\n",
    "                \n",
    "                # Reading working file as dataframe in pandas\n",
    "                \n",
    "                lab_data = pd.read_csv(sheet)\n",
    "                \n",
    "                \n",
    "                # Pulling parts of name to identify sheet for naming/moving\n",
    "\n",
    "                sheet_name = sheet.split('\\\\')[-1]\n",
    "                title = sheet_name.split('_')[2]\n",
    "            \n",
    "            \n",
    "                # Checking for data - skipping remainder of code (breaking loop) if there is no data\n",
    "\n",
    "                if np.isnan(lab_data.Absorbance[0]):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                # Continuing if data is found\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # Identifying sheet\n",
    "                    \n",
    "                    print(sheet)\n",
    "\n",
    "\n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "                    \n",
    "                    blanks_abs = []\n",
    "\n",
    "                    \n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "                    \n",
    "                    for n in range(len(lab_data)):\n",
    "                        if lab_data.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(lab_data.Absorbance[n]))\n",
    "                            \n",
    "                  \n",
    "                    # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "                            \n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "                    \n",
    "                    \n",
    "                    # If the list of acceptable blanks has fewer than three values, set must be repeated\n",
    "                    if len(good_blanks) <= 2 :\n",
    "                        print('oops')\n",
    "                    else:\n",
    "                        continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8587038805948787\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>R_Sq</th>\n",
       "      <th>P_Val</th>\n",
       "      <th>StdErr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-0.245000</td>\n",
       "      <td>0.581206</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.201250</td>\n",
       "      <td>0.556845</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-0.245000</td>\n",
       "      <td>0.581206</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>-0.110909</td>\n",
       "      <td>0.578776</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>311</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>-0.144793</td>\n",
       "      <td>0.597123</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>322</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>-0.110909</td>\n",
       "      <td>0.578776</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.114876</td>\n",
       "      <td>0.579201</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>411</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.148760</td>\n",
       "      <td>0.597592</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>422</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.114876</td>\n",
       "      <td>0.579201</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>433</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.604321</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>0.581982</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>511</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.164628</td>\n",
       "      <td>0.600551</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>522</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>0.581982</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>533</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.068889</td>\n",
       "      <td>0.605119</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>544</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.072222</td>\n",
       "      <td>0.605112</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.123871</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>611</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>-0.154516</td>\n",
       "      <td>0.632461</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>622</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.123871</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>633</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.637872</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>644</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>0.637552</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>655</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.081103</td>\n",
       "      <td>0.637378</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>700</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.148065</td>\n",
       "      <td>0.588647</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>711</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.178710</td>\n",
       "      <td>0.606538</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>722</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.148065</td>\n",
       "      <td>0.588647</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>733</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.090069</td>\n",
       "      <td>0.607083</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>744</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.093103</td>\n",
       "      <td>0.607032</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>755</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-0.105241</td>\n",
       "      <td>0.607894</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>766</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.634788</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>800</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.123871</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>811</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>-0.154516</td>\n",
       "      <td>0.632461</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>822</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.123871</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>833</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>-0.065931</td>\n",
       "      <td>0.637872</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>844</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>0.637552</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>855</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.081103</td>\n",
       "      <td>0.637378</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>866</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>-0.079167</td>\n",
       "      <td>0.671432</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>877</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.634788</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>900</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.188000</td>\n",
       "      <td>0.634661</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>911</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.219429</td>\n",
       "      <td>0.653023</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>922</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.188000</td>\n",
       "      <td>0.634661</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>933</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.116452</td>\n",
       "      <td>0.651494</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>944</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.119355</td>\n",
       "      <td>0.651084</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>955</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.130968</td>\n",
       "      <td>0.650582</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>966</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.132893</td>\n",
       "      <td>0.690255</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>977</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.145289</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>988</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.132893</td>\n",
       "      <td>0.690255</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>-0.176571</td>\n",
       "      <td>0.609893</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1011</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>0.628458</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1022</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>-0.176571</td>\n",
       "      <td>0.609893</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1033</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.108387</td>\n",
       "      <td>0.627942</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1044</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.111290</td>\n",
       "      <td>0.627609</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1055</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>-0.122903</td>\n",
       "      <td>0.627388</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1066</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>-0.124628</td>\n",
       "      <td>0.664790</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1077</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.137025</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1088</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>-0.124628</td>\n",
       "      <td>0.664790</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1099</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-0.197500</td>\n",
       "      <td>0.694536</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column     Slope  Intercept      R_Sq     P_Val    StdErr\n",
       "0     100  0.000354  -0.245000  0.581206  0.010353  0.000106\n",
       "1     200  0.000342  -0.201250  0.556845  0.013184  0.000108\n",
       "2     211  0.000354  -0.245000  0.581206  0.010353  0.000106\n",
       "3     300  0.000319  -0.110909  0.578776  0.010612  0.000096\n",
       "4     311  0.000328  -0.144793  0.597123  0.008779  0.000095\n",
       "5     322  0.000319  -0.110909  0.578776  0.010612  0.000096\n",
       "6     400  0.000320  -0.114876  0.579201  0.010566  0.000096\n",
       "7     411  0.000329  -0.148760  0.597592  0.008736  0.000095\n",
       "8     422  0.000320  -0.114876  0.579201  0.010566  0.000096\n",
       "9     433  0.000306  -0.055556  0.604321  0.008133  0.000088\n",
       "10    500  0.000323  -0.130744  0.581982  0.010272  0.000097\n",
       "11    511  0.000332  -0.164628  0.600551  0.008467  0.000096\n",
       "12    522  0.000323  -0.130744  0.581982  0.010272  0.000097\n",
       "13    533  0.000309  -0.068889  0.605119  0.008063  0.000088\n",
       "14    544  0.000309  -0.072222  0.605112  0.008064  0.000088\n",
       "15    600  0.000332  -0.123871  0.615764  0.007182  0.000093\n",
       "16    611  0.000340  -0.154516  0.632461  0.005954  0.000092\n",
       "17    622  0.000332  -0.123871  0.615764  0.007182  0.000093\n",
       "18    633  0.000319  -0.065931  0.637872  0.005593  0.000085\n",
       "19    644  0.000320  -0.068966  0.637552  0.005614  0.000085\n",
       "20    655  0.000321  -0.081103  0.637378  0.005625  0.000086\n",
       "21    700  0.000321  -0.148065  0.588647  0.009592  0.000095\n",
       "22    711  0.000329  -0.178710  0.606538  0.007941  0.000094\n",
       "23    722  0.000321  -0.148065  0.588647  0.009592  0.000095\n",
       "24    733  0.000308  -0.090069  0.607083  0.007895  0.000087\n",
       "25    744  0.000308  -0.093103  0.607032  0.007899  0.000088\n",
       "26    755  0.000310  -0.105241  0.607894  0.007826  0.000088\n",
       "27    766  0.000320  -0.100000  0.634788  0.005796  0.000086\n",
       "28    800  0.000332  -0.123871  0.615764  0.007182  0.000093\n",
       "29    811  0.000340  -0.154516  0.632461  0.005954  0.000092\n",
       "30    822  0.000332  -0.123871  0.615764  0.007182  0.000093\n",
       "31    833  0.000319  -0.065931  0.637872  0.005593  0.000085\n",
       "32    844  0.000320  -0.068966  0.637552  0.005614  0.000085\n",
       "33    855  0.000321  -0.081103  0.637378  0.005625  0.000086\n",
       "34    866  0.000334  -0.079167  0.671432  0.003719  0.000083\n",
       "35    877  0.000320  -0.100000  0.634788  0.005796  0.000086\n",
       "36    900  0.000364  -0.188000  0.634661  0.005805  0.000098\n",
       "37    911  0.000374  -0.219429  0.653023  0.004673  0.000096\n",
       "38    922  0.000364  -0.188000  0.634661  0.005805  0.000098\n",
       "39    933  0.000347  -0.116452  0.651494  0.004760  0.000090\n",
       "40    944  0.000347  -0.119355  0.651084  0.004784  0.000090\n",
       "41    955  0.000349  -0.130968  0.650582  0.004813  0.000090\n",
       "42    966  0.000367  -0.132893  0.690255  0.002907  0.000087\n",
       "43    977  0.000347  -0.145289  0.642958  0.005270  0.000092\n",
       "44    988  0.000367  -0.132893  0.690255  0.002907  0.000087\n",
       "45   1000  0.000355  -0.176571  0.609893  0.007658  0.000100\n",
       "46   1011  0.000364  -0.208000  0.628458  0.006232  0.000099\n",
       "47   1022  0.000355  -0.176571  0.609893  0.007658  0.000100\n",
       "48   1033  0.000338  -0.108387  0.627942  0.006269  0.000092\n",
       "49   1044  0.000339  -0.111290  0.627609  0.006292  0.000092\n",
       "50   1055  0.000340  -0.122903  0.627388  0.006308  0.000093\n",
       "51   1066  0.000357  -0.124628  0.664790  0.004044  0.000090\n",
       "52   1077  0.000338  -0.137025  0.619000  0.006930  0.000094\n",
       "53   1088  0.000357  -0.124628  0.664790  0.004044  0.000090\n",
       "54   1099  0.000405  -0.197500  0.694536  0.002743  0.000095"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Conc', 'Abs']\n",
    "\n",
    "curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "curve['Conc'] = curve_concentration\n",
    "curve['Abs'] = curve_absorbance\n",
    "\n",
    "points = len(curve_concentration) # Total number\n",
    "\n",
    "array = np.identity(points)\n",
    "\n",
    "for i in range(array.shape[1]):\n",
    "\n",
    "    curve[str(i)] = array[:,i]\n",
    "\n",
    "for i in range(1,points):\n",
    "\n",
    "    array = np.identity(i)\n",
    "    array = np.vstack([array, [1]*i])\n",
    "\n",
    "    if array.shape[0] != 12:\n",
    "        for j in range(12 - array.shape[0]):\n",
    "            array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "        for k in range(array.shape[1]):\n",
    "\n",
    "            curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "columns = []\n",
    "slopes = []\n",
    "intercepts = []\n",
    "rvals = []\n",
    "pvals = []\n",
    "stderrs = []\n",
    "\n",
    "parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "for column in curve.iloc[:, 2:14]:\n",
    "    \n",
    "    columns.append(column)\n",
    "    \n",
    "    count = 0\n",
    "    conc = []\n",
    "    absorb = []\n",
    "    \n",
    "    \n",
    "    for i in curve[column]: \n",
    "        if i < 1:\n",
    "            conc.append(curve.iloc[count,0])\n",
    "            absorb.append(curve.iloc[count,1])\n",
    "        count = count + 1\n",
    "        \n",
    "    slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "    \n",
    "    slopes.append(slope)\n",
    "    intercepts.append(inter)\n",
    "    rvals.append(r_val**2)\n",
    "    pvals.append(p_val)\n",
    "    stderrs.append(std)\n",
    "\n",
    "parameters['Column'] = columns\n",
    "parameters['Slope'] = slopes\n",
    "parameters['Intercept'] = intercepts\n",
    "parameters['R_Sq'] = rvals\n",
    "parameters['P_Val'] = pvals\n",
    "parameters['StdErr'] = stderrs\n",
    "\n",
    "print(parameters.R_Sq.max())\n",
    "\n",
    "if parameters['R_Sq'].max() < 0.90:\n",
    "    \n",
    "    columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "    columns = []\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    rvals = []\n",
    "    pvals = []\n",
    "    stderrs = []\n",
    "\n",
    "    parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for column in curve.iloc[:, 14:]:\n",
    "\n",
    "        columns.append(column)\n",
    "        \n",
    "        count = 0\n",
    "        conc = []\n",
    "        absorb = []\n",
    "\n",
    "\n",
    "        for i in curve[column]: \n",
    "            if i < 1:\n",
    "                conc.append(curve.iloc[count,0])\n",
    "                absorb.append(curve.iloc[count,1])\n",
    "            count = count + 1\n",
    "\n",
    "        slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "        slopes.append(slope)\n",
    "        intercepts.append(inter)\n",
    "        rvals.append(r_val**2)\n",
    "        pvals.append(p_val)\n",
    "        stderrs.append(std)\n",
    "    #     print(conc)\n",
    "    #     print(r_val**2)\n",
    "    parameters['Column'] = columns\n",
    "    parameters['Slope'] = slopes\n",
    "    parameters['Intercept'] = intercepts\n",
    "    parameters['R_Sq'] = rvals\n",
    "    parameters['P_Val'] = pvals\n",
    "    parameters['StdErr'] = stderrs\n",
    "    \n",
    "parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
