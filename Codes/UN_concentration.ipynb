{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UN_concentration Code\n",
    "#### Author: Rachel Veenstra\n",
    "#### Created: 04-12-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMR_IA_USB\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\A_1_NIT_LMR_IA_USB_03_05_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\A_1_URE_LMR_IA_USB_02_27_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\A_2_NIT_LMR_IA_USB_03_01_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\A_2_URE_LMR_IA_USB_02_27_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\B_1_NIT_LMR_IA_USB_03_01_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\B_1_URE_LMR_IA_USB_02_28_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\C_1_NIT_LMR_IA_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\C_1_URE_LMR_IA_USB_02_28_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\D_1_NIT_LMR_IA_USB_03_05_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\E_1_NIT_LMR_IA_USB_03_06_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IA_USB/Completed\\F_1_NIT_LMR_IA_USB_03_06_19.csv\n",
      "LMR_IN_USB\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_10_NIT_LMR_IN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_10_URE_LMR_IN_USB_04_02_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_1_NIT_LMR_IN_USB_03_19_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_1_URE_LMR_IN_USB_03_19_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_2_NIT_LMR_IN_USB_03_14_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_2_URE_LMR_IN_USB_03_14_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_3_NIT_LMR_IN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_3_URE_LMR_IN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_4_NIT_LMR_IN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_4_URE_LMR_IN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_5_NIT_LMR_IN_USB_03_21_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_5_URE_LMR_IN_USB_03_21_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_6_NIT_LMR_IN_USB_03_22_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_6_URE_LMR_IN_USB_03_22_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_7_NIT_LMR_IN_USB_03_22_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_7_URE_LMR_IN_USB_03_22_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_8_NIT_LMR_IN_USB_03_28_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_8_URE_LMR_IN_USB_03_28_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_9_NIT_LMR_IN_USB_03_29_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\A_9_URE_LMR_IN_USB_03_29_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\B_1_NIT_LMR_IN_USB_04_02_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\B_1_URE_LMR_IN_USB_04_02_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\B_2_NIT_LMR_IN_USB_04_02_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_IN_USB/Completed\\C_1_NIT_LMR_IN_USB_04_02_19.csv\n",
      "LMR_MN_USB\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_1_NIT_LMR_MN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_1_URE_LMR_MN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_3_NIT_LMR_MN_USB_03_15_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_3_URE_LMR_MN_USB_03_15_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_4_NIT_LMR_MN_USB_03_08_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\A_4_URE_LMR_MN_USB_03_18_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\B_1_NIT_LMR_MN_USB_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\B_1_URE_LMR_MN_USB_03_18_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\B_2_NIT_LMR_MN_USB_03_08_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\C_1_URE_LMR_MN_USB_04_02_19.csv\n",
      "BAD\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\x_BAD_CURVE_A_2_NIT_LMR_MN_USB_03_15_19.csv\n",
      "BAD\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/LMR_MN_USB/Completed\\x_BAD_CURVE_A_2_URE_LMR_MN_USB_03_15_19.csv\n",
      "USB_South_Dakota\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Pulling data to navigate to completed folders in each topic folder\n",
    "\n",
    "topic_folders = []\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    for loc in folder:\n",
    "        topic_folders.append(loc)\n",
    "        \n",
    "topic_folders = [x for x in topic_folders if x != 'Completed']\n",
    "topic_folders\n",
    "\n",
    "for i in topic_folders:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        print(i)\n",
    "\n",
    "        folder_name = str(i)\n",
    "        \n",
    "        location = \"Student_Lists/Completed/\"\n",
    "\n",
    "        sheet = i + '.csv'\n",
    "\n",
    "        id_file = '/Users/' + user + '/Desktop/Coding/StandardLab/' + location\n",
    "\n",
    "        glob.os.chdir(id_file)\n",
    "\n",
    "        id_list = pd.read_csv(sheet, header=None)\n",
    "\n",
    "        id_list.columns = ['Sample_ID']\n",
    "\n",
    "        nitrates = id_list\n",
    "        ureides = id_list\n",
    "\n",
    "        screened_data = datasheets + i + '/Completed'\n",
    "\n",
    "        glob.os.chdir(screened_data)\n",
    "\n",
    "        alldata = glob.glob(screened_data + \"/*.csv\")\n",
    "        \n",
    "        ux = 0\n",
    "        nx = 0\n",
    "\n",
    "        for loc in alldata:\n",
    "\n",
    "            analysis = (loc.split('_')[-7])\n",
    "            flag = (loc.split('_')[-11])\n",
    "\n",
    "            if flag == 'BAD':\n",
    "                print(\"BAD\")\n",
    "\n",
    "            if analysis == \"NIT\":\n",
    "\n",
    "                nit_id = []\n",
    "                nit_conc = []\n",
    "                \n",
    "                print(loc)\n",
    "                DF = pd.read_csv(loc)\n",
    "                #print(DF)\n",
    "\n",
    "                nit_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                nit_g = nit_df.groupby('Sample_ID')\n",
    "\n",
    "                nit_final=nit_df.merge(nit_g.mean(),on='Sample_ID')\n",
    "\n",
    "                nit_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "                nit_final['Type'] = DF['Type']\n",
    "\n",
    "                nit_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                nit_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "                \n",
    "                # Creating empty lists to append with 'blanks' information\n",
    "                    \n",
    "                blanks_abs = []\n",
    "\n",
    "                    \n",
    "                # Identifying blank absorbances based on 'Type' column\n",
    "                    \n",
    "                for n in range(len(nit_final)):\n",
    "                    if nit_final.Type[n] == 'B':\n",
    "                        blanks_abs.append(float(nit_final.Each[n]))\n",
    "                            \n",
    "                  \n",
    "                    # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "                            \n",
    "                good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "                \n",
    "                blank_val = np.mean(good_blanks)\n",
    "\n",
    "                c=[]\n",
    "                e=[]\n",
    "\n",
    "                for i, row in nit_final.iterrows():\n",
    "\n",
    "                     if row['Type'] == 'C':\n",
    "\n",
    "                        c.append(float(row['Sample_ID']))\n",
    "                        e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "                \n",
    "                if r_value**2 < 0.95:\n",
    "\n",
    "                        # Creating pandas dataframe for analysis\n",
    "\n",
    "                        columns = [['Conc', 'Abs']]\n",
    "\n",
    "                        curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                        curve['Conc'] = c\n",
    "                        curve['Abs'] = e\n",
    "\n",
    "\n",
    "                        # Defining the size of the possible removal matrix\n",
    "\n",
    "                        points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                        # Creating a matrix via a numpy array \n",
    "\n",
    "                        array = np.identity(points)\n",
    "\n",
    "\n",
    "                        # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                        for i in range(array.shape[1]):\n",
    "\n",
    "                            curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                        # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                        for i in range(1,points):\n",
    "\n",
    "                            array = np.identity(i)\n",
    "                            array = np.vstack([array, [1]*i])\n",
    "\n",
    "                            if array.shape[0] != 12:\n",
    "                                for j in range(12 - array.shape[0]):\n",
    "                                    array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                for k in range(array.shape[1]):\n",
    "\n",
    "                                    curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                        # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                        columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                        columns = []\n",
    "                        slopes = []\n",
    "                        intercepts = []\n",
    "                        rvals = []\n",
    "                        pvals = []\n",
    "                        stderrs = []\n",
    "\n",
    "                        parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                        for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                            columns.append(column)\n",
    "\n",
    "\n",
    "                            # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                            count = 0\n",
    "                            conc = []\n",
    "                            absorb = []\n",
    "\n",
    "\n",
    "                            # Running conditional by row in column\n",
    "\n",
    "                            for i in curve[column]: \n",
    "\n",
    "\n",
    "                                # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                if i < 1:\n",
    "                                    conc.append(curve.iloc[count,0])\n",
    "                                    absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                count = count + 1\n",
    "\n",
    "\n",
    "                            # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                            slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                            slopes.append(slope)\n",
    "                            intercepts.append(inter)\n",
    "                            rvals.append(r_val**2)\n",
    "                            pvals.append(p_val)\n",
    "                            stderrs.append(std)\n",
    "\n",
    "\n",
    "                        # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                        parameters['Column'] = columns\n",
    "                        parameters['Slope'] = slopes\n",
    "                        parameters['Intercept'] = intercepts\n",
    "                        parameters['R_Sq'] = rvals\n",
    "                        parameters['P_Val'] = pvals\n",
    "                        parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                        #print(parameters['R_Sq'].max())\n",
    "                        #print(parameters)\n",
    "\n",
    "\n",
    "                        # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                        # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                        # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                        if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                            # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "                                    \n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                        #print(parameters.R_Sq.max())\n",
    "\n",
    "                nconc = []\n",
    "\n",
    "                for i, row in nit_final.iterrows():\n",
    "\n",
    "                    nconc.append(((float(row['Mean'])*slope + intercept) - (blank_val))/(row['Sample_Wt(g)']/7.5))\n",
    "\n",
    "                nit_final['Sample_Conc(micrmol/g)'] = nconc\n",
    "\n",
    "                for i, row in nit_final.iterrows():\n",
    "\n",
    "                     if row['Type'] == 'O':\n",
    "\n",
    "                        nit_id.append(row['Sample_ID'])\n",
    "                        nit_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "                ncolumns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                ndata = pd.DataFrame(columns = ncolumns)\n",
    "\n",
    "                ndata['Sample_ID'] = nit_id\n",
    "                ndata['Conc'] = nit_conc\n",
    "\n",
    "                final_nitrates = pd.merge(nitrates, ndata, on='Sample_ID', how = 'left')\n",
    "                \n",
    "                complete_nitrates = nitrates\n",
    "                \n",
    "                complete_nitrates['N' + str(nx)] = final_nitrates['Conc']\n",
    "                \n",
    "                nx = nx+1\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "            if analysis == \"URE\":\n",
    "                \n",
    "                ure_id = []\n",
    "                ure_conc = []\n",
    "                \n",
    "                print(loc)\n",
    "                DF = pd.read_csv(loc)\n",
    "                #print(DF)\n",
    "\n",
    "                ure_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                ure_g = ure_df.groupby('Sample_ID')\n",
    "\n",
    "                ure_final = ure_df.merge(ure_g.mean(),on='Sample_ID')\n",
    "\n",
    "                ure_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "                ure_final['Type'] = DF['Type']\n",
    "\n",
    "                ure_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                ure_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "                \n",
    "                \n",
    "                # Creating empty lists to append with 'blanks' information\n",
    "                    \n",
    "                blanks_abs = []\n",
    "\n",
    "                    \n",
    "                # Identifying blank absorbances based on 'Type' column\n",
    "                    \n",
    "                for n in range(len(ure_final)):\n",
    "                    if ure_final.Type[n] == 'B':\n",
    "                        blanks_abs.append(float(ure_final.Each[n]))\n",
    "                            \n",
    "                  \n",
    "                    # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "                            \n",
    "                good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "                \n",
    "                blank_val = np.mean(good_blanks)\n",
    "\n",
    "                c=[]\n",
    "                e=[]\n",
    "\n",
    "                for i, row in ure_final.iterrows():\n",
    "\n",
    "                     if row['Type'] == 'C':\n",
    "\n",
    "                        c.append(float(row['Sample_ID']))\n",
    "                        e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "                \n",
    "                if r_value**2 < 0.95:\n",
    "\n",
    "                    # Creating pandas dataframe for analysis\n",
    "\n",
    "                    columns = [['Conc', 'Abs']]\n",
    "\n",
    "                    curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                    # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                    curve['Conc'] = c\n",
    "                    curve['Abs'] = e\n",
    "\n",
    "\n",
    "                    # Defining the size of the possible removal matrix\n",
    "\n",
    "                    points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                    # Creating a matrix via a numpy array \n",
    "\n",
    "                    array = np.identity(points)\n",
    "\n",
    "\n",
    "                    # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                    for i in range(array.shape[1]):\n",
    "\n",
    "                        curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                    # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                    for i in range(1,points):\n",
    "\n",
    "                        array = np.identity(i)\n",
    "                        array = np.vstack([array, [1]*i])\n",
    "\n",
    "                        if array.shape[0] != 12:\n",
    "                            for j in range(12 - array.shape[0]):\n",
    "                                array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                            for k in range(array.shape[1]):\n",
    "\n",
    "                                curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                    # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                    columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                    columns = []\n",
    "                    slopes = []\n",
    "                    intercepts = []\n",
    "                    rvals = []\n",
    "                    pvals = []\n",
    "                    stderrs = []\n",
    "\n",
    "                    parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                    # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                    for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                        columns.append(column)\n",
    "\n",
    "\n",
    "                        # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                        count = 0\n",
    "                        conc = []\n",
    "                        absorb = []\n",
    "\n",
    "\n",
    "                        # Running conditional by row in column\n",
    "\n",
    "                        for i in curve[column]: \n",
    "\n",
    "\n",
    "                            # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                            if i < 1:\n",
    "                                conc.append(curve.iloc[count,0])\n",
    "                                absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                            # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                            count = count + 1\n",
    "\n",
    "\n",
    "                        # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                        slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                        slopes.append(slope)\n",
    "                        intercepts.append(inter)\n",
    "                        rvals.append(r_val**2)\n",
    "                        pvals.append(p_val)\n",
    "                        stderrs.append(std)\n",
    "\n",
    "\n",
    "                    # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                    parameters['Column'] = columns\n",
    "                    parameters['Slope'] = slopes\n",
    "                    parameters['Intercept'] = intercepts\n",
    "                    parameters['R_Sq'] = rvals\n",
    "                    parameters['P_Val'] = pvals\n",
    "                    parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                    ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                    #print(parameters['R_Sq'].max())\n",
    "                    #print(parameters)\n",
    "\n",
    "\n",
    "                    # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                    # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                    # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                    if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                        # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                        columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                        columns = []\n",
    "                        slopes = []\n",
    "                        intercepts = []\n",
    "                        rvals = []\n",
    "                        pvals = []\n",
    "                        stderrs = []\n",
    "\n",
    "                        parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                        for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                            columns.append(column)\n",
    "\n",
    "\n",
    "                            # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                            count = 0\n",
    "                            conc = []\n",
    "                            absorb = []\n",
    "\n",
    "\n",
    "                            # Running conditional by row in column\n",
    "                                    \n",
    "                            for i in curve[column]: \n",
    "\n",
    "\n",
    "                                # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                if i < 1:\n",
    "                                    conc.append(curve.iloc[count,0])\n",
    "                                    absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                count = count + 1\n",
    "\n",
    "\n",
    "                            # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                            slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                            slopes.append(slope)\n",
    "                            intercepts.append(inter)\n",
    "                            rvals.append(r_val**2)\n",
    "                            pvals.append(p_val)\n",
    "                            stderrs.append(std)\n",
    "\n",
    "                        # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                        parameters['Column'] = columns\n",
    "                        parameters['Slope'] = slopes\n",
    "                        parameters['Intercept'] = intercepts\n",
    "                        parameters['R_Sq'] = rvals\n",
    "                        parameters['P_Val'] = pvals\n",
    "                        parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                    # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                    #print(parameters.R_Sq.max())\n",
    "                \n",
    "                conc = []\n",
    "                \n",
    "                for i, row in ure_final.iterrows():\n",
    "\n",
    "                    conc.append(((float(row['Mean'])*slope + intercept)-(blank_val))/(row['Sample_Wt(g)']/7.5))\n",
    "\n",
    "                ure_final['Sample_Conc(micrmol/g)'] = conc\n",
    "\n",
    "                for i, row in ure_final.iterrows():\n",
    "\n",
    "                     if row['Type'] == 'O':\n",
    "\n",
    "                        ure_id.append(row['Sample_ID'])\n",
    "                        ure_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "                columns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                data = pd.DataFrame(columns = columns)\n",
    "\n",
    "                data['Sample_ID'] = ure_id\n",
    "                data['Conc'] = ure_conc \n",
    "                \n",
    "                final_ureides = pd.merge(ureides, data, on='Sample_ID', how = 'left')  \n",
    "\n",
    "                complete_ureides = ureides\n",
    "                \n",
    "                complete_ureides['U' + str(ux)] = final_ureides['Conc']\n",
    "                \n",
    "                ux = ux+1\n",
    "            \n",
    "        save_loc = '/Users/' + user + '/Desktop/Coding/StandardLab/Results/'\n",
    "\n",
    "        glob.os.chdir(save_loc)\n",
    "        \n",
    "        complete_ureides.to_csv('Results_URE_' + folder_name + '.csv', index=False)\n",
    "        complete_nitrates.to_csv('Results_NIT_' + folder_name + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "        ## BUG AS OF 4-12-19 .... BOTH FILES SAVED ARE IDENTICAL ... SOMEHOW FILES ARE BEING OVREWRITTEN? PROBABLY A NESTING ISSUE.\n",
    "        \n",
    "        \n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
