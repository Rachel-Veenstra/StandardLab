{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UN_concentration Code\n",
    "#### Author: Rachel Veenstra\n",
    "#### Created: 04-12-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_RAU_Processed_Sheets\n",
      "MS_ASH_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_1_NIT_MS_ASH_LI_12_17_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_2_NIT_MS_ASH_LI_12_17_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_3_NIT_MS_ASH_LI_12_18_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_4_NIT_MS_ASH_LI_12_18_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_5_NIT_MS_ASH_LI_12_19_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_6_NIT_MS_ASH_LI_00_00_00.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_8_NIT_MS_ASH_LI_12_20_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_2_NIT_MS_ASH_LI_01_03_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_3_NIT_MS_ASH_LI_01_04_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_5_NIT_MS_ASH_LI_01_04_19.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_7_NIT_MS_ASH_LI_12_20_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_1_URE_MS_ASH_LI_11_15_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_2_URE_MS_ASH_LI_11_16_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_3_URE_MS_ASH_LI_11_19_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_5_URE_MS_ASH_LI_11_20_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_6_URE_MS_ASH_LI_11_21_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_7_URE_MS_ASH_LI_12_05_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\A_9_URE_MS_ASH_LI_12_05_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_1_URE_MS_ASH_LI_12_10_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_6_URE_MS_ASH_LI_01_29_19.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_ASH_LI/Completed\\B_8_URE_MS_ASH_LI_11_20_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_ASH_LI\\Completed\n",
      "MS_GH_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_15_NIT_MS_GH_LI_10_04_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_16_NIT_MS_GH_LI_10_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_17_NIT_MS_GH_LI_10_05_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_1_NIT_MS_GH_LI_07_12_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_3_NIT_MS_GH_LI_07_13_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_8_NIT_MS_GH_LI_07_09_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_9_NIT_MS_GH_LI_07_10_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_2_NIT_MS_GH_LI_07_16_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_7_NIT_MS_GH_LI_10_08_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_8_NIT_MS_GH_LI_10_08_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\NO_BLANKS_QB_3_NIT_MS_GH_LI_07_16_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\NO_BLANKS_QB_4_NIT_MS_GH_LI_07_17_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\QA_2_NIT_MS_GH_LI_07_12_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\QA_4_NIT_MS_GH_LI_07_13_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\QA_7_NIT_MS_GH_LI_07_13_18.csv\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_15_URE_MS_GH_LI_10_01_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_16_URE_MS_GH_LI_10_02_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_17_URE_MS_GH_LI_10_02_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_1_URE_MS_GH_LI_06_25_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_2_URE_MS_GH_LI_06_28_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_3_URE_MS_GH_LI_07_02_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_4_URE_MS_GH_LI_07_05_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_7_URE_MS_GH_LI_07_05_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_8_URE_MS_GH_LI_07_09_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\A_9_URE_MS_GH_LI_07_10_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_5_URE_MS_GH_LI_07_27_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\B_6_URE_MS_GH_LI_10_03_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_GH_LI/Completed\\NO_BLANKS_QB_1_URE_MS_GH_LI_00_00_00.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_GH_LI\\Completed\n",
      "MS_OTT_LI\n",
      "/Users/rveenstra/Desktop/Coding/StandardLab/Lab_Sheets/MS_OTT_LI/Completed\\A_4_URE_MS_OTT_LI_11_28_18.csv\n",
      "C:\\Users\\rveenstra\\Desktop\\Coding\\StandardLab\\Lab_Sheets\\MS_OTT_LI\\Completed\n",
      "RAU COMPLETED\n",
      "New folder\n",
      "LMR_IA_USB\n",
      "LMR_IN_USB\n",
      "LMR_MN_USB\n",
      "LMR_SD_USB\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Identifying directory of lab sheets for quality screening\n",
    "\n",
    "path = str(glob.os.getcwd())\n",
    "\n",
    "user = path.split('\\\\')[2]\n",
    "\n",
    "folder = \"Lab_Sheets/\"\n",
    "\n",
    "datasheets = '/Users/' + user + '/Desktop/Coding/StandardLab/' + folder\n",
    "\n",
    "glob.os.chdir(datasheets)\n",
    "\n",
    "\n",
    "\n",
    "# Pulling data to navigate to completed folders in each topic folder\n",
    "\n",
    "topic_folders = []\n",
    "\n",
    "for x, folder, file in os.walk(datasheets):\n",
    "    for loc in folder:\n",
    "        topic_folders.append(loc)\n",
    "        \n",
    "topic_folders = [x for x in topic_folders if x != 'Completed']\n",
    "topic_folders\n",
    "\n",
    "for i in topic_folders:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        print(i)\n",
    "        \n",
    "        folder_name = str(i)\n",
    "        \n",
    "        location = \"Student_Lists/Completed/\"\n",
    "\n",
    "        sheet = i + '.csv'\n",
    "\n",
    "        id_file = '/Users/' + user + '/Desktop/Coding/StandardLab/' + location\n",
    "\n",
    "        glob.os.chdir(id_file)\n",
    "\n",
    "        u_id_list = pd.read_csv(sheet, header=None)\n",
    "\n",
    "        u_id_list.columns = ['Sample_ID']\n",
    "\n",
    "        ureides = u_id_list\n",
    "        \n",
    "        n_id_list = pd.read_csv(sheet, header=None)\n",
    "\n",
    "        n_id_list.columns = ['Sample_ID']\n",
    "        \n",
    "        nitrates = n_id_list\n",
    "        \n",
    "        screened_data = datasheets + i + '/Completed'\n",
    "\n",
    "        glob.os.chdir(screened_data)\n",
    "\n",
    "        alldata = glob.glob(screened_data + \"/*.csv\")\n",
    "     \n",
    "        for loc in alldata:\n",
    "            \n",
    "            analysis = (loc.split('_')[-7])\n",
    "            flag = (loc.split('_')[-11])\n",
    "            name = (loc.split('\\\\')[-1])\n",
    "\n",
    "            if flag != 'BAD':\n",
    "\n",
    "                if analysis == \"NIT\":\n",
    "\n",
    "                    var_id = []\n",
    "                    nit_id = []\n",
    "                    nit_conc = []\n",
    "\n",
    "                    print(loc)\n",
    "                    DF = pd.read_csv(loc)\n",
    "                    #print(DF)\n",
    "\n",
    "                    nit_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                    nit_g = nit_df.groupby('Sample_ID')\n",
    "\n",
    "                    nit_final=nit_df.merge(nit_g.mean(),on='Sample_ID')\n",
    "\n",
    "                    nit_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "\n",
    "                    # Marking values with high variance\n",
    "\n",
    "                    sample_data_var = nit_df.merge((abs((nit_g.max() - nit_g.min())) / (nit_g.max())), on='Sample_ID')\n",
    "\n",
    "                    sample_data_var['Type'] = DF['Type']\n",
    "\n",
    "                    for i, row in sample_data_var.iterrows():\n",
    "\n",
    "                        if row['Type'] == \"O\":\n",
    "\n",
    "                            if float(row['Absorbance_y']) > 0.1:\n",
    "                                var_id.append('x_')\n",
    "                            else:\n",
    "                                var_id.append('')\n",
    "\n",
    "                    nit_final['Type'] = DF['Type']\n",
    "\n",
    "                    nit_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                    nit_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "\n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "\n",
    "                    blanks_abs = []\n",
    "\n",
    "\n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "\n",
    "                    for n in range(len(nit_final)):\n",
    "                        if nit_final.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(nit_final.Each[n]))\n",
    "\n",
    "\n",
    "                        # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "\n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "\n",
    "                    blank_val = np.mean(good_blanks)\n",
    "\n",
    "                    c=[]\n",
    "                    e=[]\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'C':\n",
    "\n",
    "                            c.append(float(row['Sample_ID']))\n",
    "                            e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                    slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "\n",
    "                    if r_value**2 < 0.95:\n",
    "\n",
    "                            # Creating pandas dataframe for analysis\n",
    "\n",
    "                            columns = [['Conc', 'Abs']]\n",
    "\n",
    "                            curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                            curve['Conc'] = c\n",
    "                            curve['Abs'] = e\n",
    "\n",
    "\n",
    "                            # Defining the size of the possible removal matrix\n",
    "\n",
    "                            points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                            # Creating a matrix via a numpy array \n",
    "\n",
    "                            array = np.identity(points)\n",
    "\n",
    "\n",
    "                            # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                            for i in range(array.shape[1]):\n",
    "\n",
    "                                curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                            # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                            for i in range(1,points):\n",
    "\n",
    "                                array = np.identity(i)\n",
    "                                array = np.vstack([array, [1]*i])\n",
    "\n",
    "                                if array.shape[0] != 12:\n",
    "                                    for j in range(12 - array.shape[0]):\n",
    "                                        array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                    for k in range(array.shape[1]):\n",
    "\n",
    "                                        curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                            # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "\n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                            ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                            #print(parameters['R_Sq'].max())\n",
    "                            #print(parameters)\n",
    "\n",
    "\n",
    "                            # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                            # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                            # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                            if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                                # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                                columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                                columns = []\n",
    "                                slopes = []\n",
    "                                intercepts = []\n",
    "                                rvals = []\n",
    "                                pvals = []\n",
    "                                stderrs = []\n",
    "\n",
    "                                parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                                # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                                for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                    columns.append(column)\n",
    "\n",
    "\n",
    "                                    # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                    count = 0\n",
    "                                    conc = []\n",
    "                                    absorb = []\n",
    "\n",
    "\n",
    "                                    # Running conditional by row in column\n",
    "\n",
    "                                    for i in curve[column]: \n",
    "\n",
    "\n",
    "                                        # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                        if i < 1:\n",
    "                                            conc.append(curve.iloc[count,0])\n",
    "                                            absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                        # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                        count = count + 1\n",
    "\n",
    "\n",
    "                                    # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                    slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                    slopes.append(slope)\n",
    "                                    intercepts.append(inter)\n",
    "                                    rvals.append(r_val**2)\n",
    "                                    pvals.append(p_val)\n",
    "                                    stderrs.append(std)\n",
    "\n",
    "                                # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                                parameters['Column'] = columns\n",
    "                                parameters['Slope'] = slopes\n",
    "                                parameters['Intercept'] = intercepts\n",
    "                                parameters['R_Sq'] = rvals\n",
    "                                parameters['P_Val'] = pvals\n",
    "                                parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                            # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                            #print(parameters.R_Sq.max())\n",
    "\n",
    "                    nconc = []\n",
    "                    nit_conc_var = []\n",
    "\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                        nconc.append(((row['Mean'] - blank_val)*slope + intercept)/((row['Sample_Wt(g)']*1000/7.5)))\n",
    "\n",
    "                    nit_final['Sample_Conc(micrmol/g)'] = nconc\n",
    "\n",
    "                    for i, row in nit_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'O':\n",
    "\n",
    "                            nit_id.append(row['Sample_ID'])\n",
    "                            nit_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "\n",
    "                    for i in range(len(nit_conc)):\n",
    "                        nit_conc_var.append(str(var_id[i]) + str(nit_conc[i]))       \n",
    "\n",
    "\n",
    "                    ncolumns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                    ndata = pd.DataFrame(columns = ncolumns)\n",
    "\n",
    "                    ndata['Sample_ID'] = nit_id\n",
    "                    ndata['Conc'] = nit_conc_var\n",
    "\n",
    "                    final_nitrates = pd.merge(nitrates, ndata, on='Sample_ID', how = 'left')\n",
    "\n",
    "                    complete_nitrates = nitrates\n",
    "\n",
    "                    complete_nitrates[str(name)] = final_nitrates['Conc']\n",
    "\n",
    "        \n",
    "        \n",
    "        for loc in alldata:\n",
    "\n",
    "            analysis = (loc.split('_')[-7])\n",
    "            flag = (loc.split('_')[-11])\n",
    "            name = (loc.split('\\\\')[-1])\n",
    "\n",
    "            if flag != 'BAD':\n",
    "        \n",
    "                if analysis == \"URE\":\n",
    "        \n",
    "                    var_id = []\n",
    "                    ure_id = []\n",
    "                    ure_conc = []\n",
    "\n",
    "                    print(loc)\n",
    "                    DF = pd.read_csv(loc)\n",
    "                    #print(DF)\n",
    "\n",
    "                    ure_df = DF[['Sample_ID', 'Absorbance']]\n",
    "\n",
    "                    ure_g = ure_df.groupby('Sample_ID')\n",
    "\n",
    "                    ure_final = ure_df.merge(ure_g.mean(),on='Sample_ID')\n",
    "\n",
    "                    ure_final.rename(columns = {'Absorbance_x':'Each', 'Absorbance_y':'Mean'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "                    # Marking values with high variance\n",
    "\n",
    "                    sample_data_var = ure_df.merge((abs((ure_g.max() - ure_g.min())) / (ure_g.max())), on='Sample_ID')\n",
    "\n",
    "                    sample_data_var['Type'] = DF['Type']\n",
    "\n",
    "                    for i, row in sample_data_var.iterrows():\n",
    "\n",
    "                        if row['Type'] == \"O\":\n",
    "\n",
    "                            if float(row['Absorbance_y']) > 0.1:\n",
    "                                var_id.append('x_')\n",
    "                            else:\n",
    "                                var_id.append('')\n",
    "                  \n",
    "                    ure_final['Type'] = DF['Type']\n",
    "\n",
    "                    ure_final['Sample_Wt(g)'] = DF['Sample_Wt(g)']\n",
    "\n",
    "                    ure_final['Sample_Wt(g)'].replace(np.nan, 0.3, inplace= True)\n",
    "\n",
    "\n",
    "                    # Creating empty lists to append with 'blanks' information\n",
    "\n",
    "                    blanks_abs = []\n",
    "\n",
    "\n",
    "                    # Identifying blank absorbances based on 'Type' column\n",
    "\n",
    "                    for n in range(len(ure_final)):\n",
    "                        if ure_final.Type[n] == 'B':\n",
    "                            blanks_abs.append(float(ure_final.Each[n]))\n",
    "\n",
    "\n",
    "                        # Creating a conditional to filter blank absorbances outside of acceptable range\n",
    "\n",
    "                    good_blanks = [x for x in blanks_abs if x < 0.1 and x > -0.1]\n",
    "\n",
    "                    blank_val = np.mean(good_blanks)\n",
    "\n",
    "                    c=[]\n",
    "                    e=[]\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                         if row['Type'] == 'C':\n",
    "\n",
    "                            c.append(float(row['Sample_ID']))\n",
    "                            e.append(float(row['Each']))\n",
    "\n",
    "\n",
    "                    slope, intercept, r_value, p_value, std_err = stats.linregress(e, c)\n",
    "\n",
    "                    if r_value**2 < 0.95:\n",
    "\n",
    "                        # Creating pandas dataframe for analysis\n",
    "\n",
    "                        columns = [['Conc', 'Abs']]\n",
    "\n",
    "                        curve = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Assigning values to concentration and absorbance columns\n",
    "\n",
    "                        curve['Conc'] = c\n",
    "                        curve['Abs'] = e\n",
    "\n",
    "\n",
    "                        # Defining the size of the possible removal matrix\n",
    "\n",
    "                        points = len(c) # Total number of datapoints\n",
    "\n",
    "\n",
    "                        # Creating a matrix via a numpy array \n",
    "\n",
    "                        array = np.identity(points)\n",
    "\n",
    "\n",
    "                        # Using a for-loop to generate new columns in the new pandas df containing values from decision matrix\n",
    "\n",
    "                        for i in range(array.shape[1]):\n",
    "\n",
    "                            curve[str(i)] = array[:,i]\n",
    "\n",
    "\n",
    "                        # Appending 0's and 1's to df for all combinations of 1 and 2-point removal\n",
    "\n",
    "                        for i in range(1,points):\n",
    "\n",
    "                            array = np.identity(i)\n",
    "                            array = np.vstack([array, [1]*i])\n",
    "\n",
    "                            if array.shape[0] != 12:\n",
    "                                for j in range(12 - array.shape[0]):\n",
    "                                    array = np.vstack([array, [0]*array.shape[1]])\n",
    "\n",
    "                                for k in range(array.shape[1]):\n",
    "\n",
    "                                    curve[str(i)+str(k)+str(k)] = array[:,k]\n",
    "\n",
    "\n",
    "                        # Assigning column names and creating pandas dataframe to hold/analyze \"new\" curve parameters\n",
    "\n",
    "                        columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                        columns = []\n",
    "                        slopes = []\n",
    "                        intercepts = []\n",
    "                        rvals = []\n",
    "                        pvals = []\n",
    "                        stderrs = []\n",
    "\n",
    "                        parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                        # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH ONE POINT IS REMOVED)\n",
    "\n",
    "                        for column in curve.iloc[:, 2:14]:\n",
    "\n",
    "                            columns.append(column)\n",
    "\n",
    "\n",
    "                            # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                            count = 0\n",
    "                            conc = []\n",
    "                            absorb = []\n",
    "\n",
    "\n",
    "                            # Running conditional by row in column\n",
    "\n",
    "                            for i in curve[column]: \n",
    "\n",
    "\n",
    "                                # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                if i < 1:\n",
    "                                    conc.append(curve.iloc[count,0])\n",
    "                                    absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                # Appending counter to reflect the next row for iteration\n",
    "\n",
    "                                count = count + 1\n",
    "\n",
    "\n",
    "                            # Assigning variables to outputs from stats.linregress() function and appending list with column values\n",
    "\n",
    "                            slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                            slopes.append(slope)\n",
    "                            intercepts.append(inter)\n",
    "                            rvals.append(r_val**2)\n",
    "                            pvals.append(p_val)\n",
    "                            stderrs.append(std)\n",
    "\n",
    "\n",
    "                        # Assigning regression values to columns in parameters dataframe    \n",
    "\n",
    "                        parameters['Column'] = columns\n",
    "                        parameters['Slope'] = slopes\n",
    "                        parameters['Intercept'] = intercepts\n",
    "                        parameters['R_Sq'] = rvals\n",
    "                        parameters['P_Val'] = pvals\n",
    "                        parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        ## TO SEE THE PARAMETERS AND PRINT THE R^2 CALCULATED BY REMOVAL OF ONE POINT OF THE CURVE:\n",
    "\n",
    "                        #print(parameters['R_Sq'].max())\n",
    "                        #print(parameters)\n",
    "\n",
    "\n",
    "                        # Creating a second conditional for r^2 based on a matrix that calculates optional r^2 values based\n",
    "                        # on removal of two curve points ... THIS CODE WILL ONLY BE RUN IF THE HIGHEST POSSIBLE R^2 VALUE IN\n",
    "                        # THE PREVIOUS DATAFRAME IS LESS THAN 0.95\n",
    "\n",
    "                        if parameters['R_Sq'].max() < 0.95:\n",
    "\n",
    "\n",
    "                            # OVERWRITING previous column names and dataframe to hold/analyze \"new\" secondary curve parameters\n",
    "\n",
    "                            columns = ['Column', 'Slope', 'Intercept', 'R_Val', 'P_Val', 'StdErr']\n",
    "\n",
    "                            columns = []\n",
    "                            slopes = []\n",
    "                            intercepts = []\n",
    "                            rvals = []\n",
    "                            pvals = []\n",
    "                            stderrs = []\n",
    "\n",
    "                            parameters = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "                            # Running conditional by column in new df (ONLY CONSIDERING THE COLUMNS OF THE MATRIX IN WHICH TWO POINTS ARE REMOVED)\n",
    "\n",
    "                            for column in curve.iloc[:, 14:]:\n",
    "\n",
    "                                columns.append(column)\n",
    "\n",
    "\n",
    "                                # Creating iterations counter and creating lists to append in for-loop\n",
    "\n",
    "                                count = 0\n",
    "                                conc = []\n",
    "                                absorb = []\n",
    "\n",
    "\n",
    "                                # Running conditional by row in column\n",
    "\n",
    "                                for i in curve[column]: \n",
    "\n",
    "\n",
    "                                    # Conditional \"removing\" rows of column by not appending values to respective lists if value is 1\n",
    "\n",
    "                                    if i < 1:\n",
    "                                        conc.append(curve.iloc[count,0])\n",
    "                                        absorb.append(curve.iloc[count,1])\n",
    "\n",
    "\n",
    "                                    # Appending counter to reflect the next row for iteration    \n",
    "\n",
    "                                    count = count + 1\n",
    "\n",
    "\n",
    "                                # Assigning variables to outputs from stats.linregress() function and appending list with column values    \n",
    "\n",
    "                                slope, inter, r_val, p_val, std = stats.linregress(conc, absorb)\n",
    "\n",
    "                                slopes.append(slope)\n",
    "                                intercepts.append(inter)\n",
    "                                rvals.append(r_val**2)\n",
    "                                pvals.append(p_val)\n",
    "                                stderrs.append(std)\n",
    "\n",
    "                            # Assigning regression values to columns in parameters dataframe \n",
    "\n",
    "                            parameters['Column'] = columns\n",
    "                            parameters['Slope'] = slopes\n",
    "                            parameters['Intercept'] = intercepts\n",
    "                            parameters['R_Sq'] = rvals\n",
    "                            parameters['P_Val'] = pvals\n",
    "                            parameters['StdErr'] = stderrs\n",
    "\n",
    "\n",
    "                        # Displaying FINAL optimized r^2 value ... either from removing one or two points (df overwritten if two points)\n",
    "\n",
    "                        #print(parameters.R_Sq.max())\n",
    "\n",
    "                    conc = []\n",
    "                    ure_conc_var = []\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                        conc.append((((row['Mean'] - blank_val)*slope + intercept)/((row['Sample_Wt(g)']*1000/7.5)))*4)\n",
    "\n",
    "                    ure_final['Sample_Conc(micrmol/g)'] = conc\n",
    "\n",
    "\n",
    "\n",
    "                    for i, row in ure_final.iterrows():\n",
    "\n",
    "                        if row['Type'] == 'O':\n",
    "\n",
    "                            ure_id.append(row['Sample_ID'])\n",
    "                            ure_conc.append(row['Sample_Conc(micrmol/g)'])\n",
    "\n",
    "                    for i in range(len(ure_conc)):\n",
    "                        ure_conc_var.append(str(var_id[i]) + str(ure_conc[i]))\n",
    "\n",
    "                    columns = ['Sample_ID', 'Conc']\n",
    "\n",
    "                    udata = pd.DataFrame(columns = columns)\n",
    "\n",
    "                    udata['Sample_ID'] = ure_id\n",
    "                    udata['Conc'] = ure_conc_var \n",
    "\n",
    "                    final_ureides = pd.merge(ureides, udata, on='Sample_ID', how = 'left')  \n",
    "\n",
    "                    complete_ureides = ureides\n",
    "\n",
    "                    complete_ureides[str(name)] = final_ureides['Conc']\n",
    "                \n",
    "                    print(glob.os.getcwd())\n",
    "                    \n",
    "                    \n",
    "        study_name = str(folder_name.split('_')[-3]) + \"_\" + str(folder_name.split('_')[-1])\n",
    "        \n",
    "        \n",
    "        # Creating new folder for saving results from each study\n",
    "        \n",
    "        result_folder = '/Users/' + user + '/Desktop/Coding/StandardLab/Results/' + study_name\n",
    "    \n",
    "        if not glob.os.path.exists(result_folder):\n",
    "            glob.os.makedirs(result_folder)\n",
    "        \n",
    "\n",
    "        glob.os.chdir(result_folder)\n",
    "        \n",
    "        complete_ureides.to_csv('Results_URE_' + folder_name + '.csv', index=False)\n",
    "        complete_nitrates.to_csv('Results_NIT_' + folder_name + '.csv', index=False)\n",
    "        \n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "### CURRENT ROADBLOCK - Moving folder to different folder    \n",
    "    \n",
    "    \n",
    "    # Creating new folder for processed datasheets, to avoid multiple runs of same data\n",
    "            \n",
    "#     processed_folder = '/Users/' + user + '/Desktop/Coding/StandardLab/Lab_Sheets/0_RAU_Processed_Sheets/'\n",
    "    \n",
    "#     if not glob.os.path.exists(processed_folder):\n",
    "#         glob.os.makedirs(processed_folder)\n",
    "        \n",
    "        \n",
    "#     glob.os.chdir(processed_folder)\n",
    "    \n",
    "#     # Moving location folder to processed folder to avoid re-running\n",
    "            \n",
    "#     shutil.move(str(folder_name), (processed_folder + folder_name + '/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
